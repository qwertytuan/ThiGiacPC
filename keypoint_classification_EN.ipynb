{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 12:47:23.368687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744955243.386479   34857 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744955243.391830   34857 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1744955243.406203   34857 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744955243.406231   34857 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744955243.406233   34857 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744955243.406236   34857 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-18 12:47:23.411231: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
        "model_save_path = 'model/keypoint_classifier/keypoint_classifier.keras'\n",
        "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1744955248.687517   34857 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2611 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m860\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m77\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,147</span> (4.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,147\u001b[0m (4.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,147</span> (4.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,147\u001b[0m (4.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1744955250.436075   34941 service.cc:152] XLA service 0x7bc580003540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1744955250.436098   34941 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
            "2025-04-18 12:47:30.471206: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1744955250.651612   34941 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1773 - loss: 1.9379"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1744955252.194891   34941 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1789 - loss: 1.9357\n",
            "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.1797 - loss: 1.9346 - val_accuracy: 0.4133 - val_loss: 1.7420\n",
            "Epoch 2/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3723 - loss: 1.7019\n",
            "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3731 - loss: 1.7006 - val_accuracy: 0.5286 - val_loss: 1.4019\n",
            "Epoch 3/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4935 - loss: 1.4443 \n",
            "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4905 - loss: 1.4309 - val_accuracy: 0.6230 - val_loss: 1.1534\n",
            "Epoch 4/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5519 - loss: 1.2641 \n",
            "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5510 - loss: 1.2543 - val_accuracy: 0.6747 - val_loss: 0.9911\n",
            "Epoch 5/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5738 - loss: 1.1431 \n",
            "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5753 - loss: 1.1405 - val_accuracy: 0.6901 - val_loss: 0.8943\n",
            "Epoch 6/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5830 - loss: 1.0900 \n",
            "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5844 - loss: 1.0833 - val_accuracy: 0.7210 - val_loss: 0.8251\n",
            "Epoch 7/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 1.0242 \n",
            "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6176 - loss: 1.0168 - val_accuracy: 0.7260 - val_loss: 0.7762\n",
            "Epoch 8/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.9929 \n",
            "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 0.9776 - val_accuracy: 0.7541 - val_loss: 0.7312\n",
            "Epoch 9/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6467 - loss: 0.9450 \n",
            "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6436 - loss: 0.9417 - val_accuracy: 0.7654 - val_loss: 0.6980\n",
            "Epoch 10/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6482 - loss: 0.9196 \n",
            "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 0.9083 - val_accuracy: 0.7813 - val_loss: 0.6697\n",
            "Epoch 11/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6381 - loss: 0.8944 \n",
            "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6433 - loss: 0.8889 - val_accuracy: 0.7990 - val_loss: 0.6485\n",
            "Epoch 12/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.8292 \n",
            "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6937 - loss: 0.8365 - val_accuracy: 0.8162 - val_loss: 0.6202\n",
            "Epoch 13/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6759 - loss: 0.8490 \n",
            "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6820 - loss: 0.8404 - val_accuracy: 0.8190 - val_loss: 0.6078\n",
            "Epoch 14/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7096 - loss: 0.7908 \n",
            "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7042 - loss: 0.7996 - val_accuracy: 0.8258 - val_loss: 0.5877\n",
            "Epoch 15/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6952 - loss: 0.7988 \n",
            "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6973 - loss: 0.7959 - val_accuracy: 0.8221 - val_loss: 0.5711\n",
            "Epoch 16/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.7525 \n",
            "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.7621 - val_accuracy: 0.8308 - val_loss: 0.5556\n",
            "Epoch 17/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.7902 \n",
            "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.7771 - val_accuracy: 0.8421 - val_loss: 0.5438\n",
            "Epoch 18/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.7481\n",
            "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7284 - loss: 0.7468 - val_accuracy: 0.8444 - val_loss: 0.5251\n",
            "Epoch 19/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.7410\n",
            "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.7409 - val_accuracy: 0.8407 - val_loss: 0.5214\n",
            "Epoch 20/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.7463 \n",
            "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7281 - loss: 0.7381 - val_accuracy: 0.8480 - val_loss: 0.5067\n",
            "Epoch 21/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.7081\n",
            "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7344 - loss: 0.7083 - val_accuracy: 0.8598 - val_loss: 0.4950\n",
            "Epoch 22/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7470 - loss: 0.7022 \n",
            "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7440 - loss: 0.7018 - val_accuracy: 0.8662 - val_loss: 0.4810\n",
            "Epoch 23/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.6730\n",
            "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7518 - loss: 0.6761 - val_accuracy: 0.8639 - val_loss: 0.4711\n",
            "Epoch 24/1000\n",
            "\u001b[1m44/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7493 - loss: 0.6906\n",
            "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7475 - loss: 0.6935 - val_accuracy: 0.8589 - val_loss: 0.4707\n",
            "Epoch 25/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7476 - loss: 0.6754\n",
            "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7467 - loss: 0.6779 - val_accuracy: 0.8643 - val_loss: 0.4704\n",
            "Epoch 26/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7491 - loss: 0.6889\n",
            "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7488 - loss: 0.6886 - val_accuracy: 0.8603 - val_loss: 0.4655\n",
            "Epoch 27/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7521 - loss: 0.6808\n",
            "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7520 - loss: 0.6802 - val_accuracy: 0.8743 - val_loss: 0.4536\n",
            "Epoch 28/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7430 - loss: 0.6887\n",
            "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7435 - loss: 0.6880 - val_accuracy: 0.8693 - val_loss: 0.4499\n",
            "Epoch 29/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.6974\n",
            "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7409 - loss: 0.6971 - val_accuracy: 0.8743 - val_loss: 0.4441\n",
            "Epoch 30/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7596 - loss: 0.6458\n",
            "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.6464 - val_accuracy: 0.8775 - val_loss: 0.4330\n",
            "Epoch 31/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.6331\n",
            "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.6351 - val_accuracy: 0.8857 - val_loss: 0.4236\n",
            "Epoch 32/1000\n",
            "\u001b[1m36/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7554 - loss: 0.6587\n",
            "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 0.6577 - val_accuracy: 0.8793 - val_loss: 0.4239\n",
            "Epoch 33/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7685 - loss: 0.6345\n",
            "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.6356 - val_accuracy: 0.8825 - val_loss: 0.4129\n",
            "Epoch 34/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7610 - loss: 0.6467\n",
            "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7614 - loss: 0.6467 - val_accuracy: 0.8802 - val_loss: 0.4160\n",
            "Epoch 35/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.6492\n",
            "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7676 - loss: 0.6475 - val_accuracy: 0.8820 - val_loss: 0.4147\n",
            "Epoch 36/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.6453\n",
            "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7661 - loss: 0.6443 - val_accuracy: 0.8798 - val_loss: 0.4030\n",
            "Epoch 37/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7682 - loss: 0.6464\n",
            "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7683 - loss: 0.6452 - val_accuracy: 0.8843 - val_loss: 0.3998\n",
            "Epoch 38/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.6388\n",
            "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7612 - loss: 0.6363 - val_accuracy: 0.8816 - val_loss: 0.3910\n",
            "Epoch 39/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7584 - loss: 0.6475\n",
            "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.6431 - val_accuracy: 0.8870 - val_loss: 0.3879\n",
            "Epoch 40/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.6062\n",
            "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7781 - loss: 0.6110 - val_accuracy: 0.8925 - val_loss: 0.3842\n",
            "Epoch 41/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7588 - loss: 0.6568\n",
            "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6524 - val_accuracy: 0.8888 - val_loss: 0.3838\n",
            "Epoch 42/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.5952\n",
            "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.5995 - val_accuracy: 0.8861 - val_loss: 0.3795\n",
            "Epoch 43/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.6325\n",
            "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7657 - loss: 0.6286 - val_accuracy: 0.8907 - val_loss: 0.3727\n",
            "Epoch 44/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7742 - loss: 0.6102\n",
            "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.6094 - val_accuracy: 0.8956 - val_loss: 0.3681\n",
            "Epoch 45/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7711 - loss: 0.6278\n",
            "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7715 - loss: 0.6265 - val_accuracy: 0.8925 - val_loss: 0.3710\n",
            "Epoch 46/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: 0.6014\n",
            "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7860 - loss: 0.6021 - val_accuracy: 0.8920 - val_loss: 0.3635\n",
            "Epoch 47/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.6049\n",
            "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7794 - loss: 0.6038 - val_accuracy: 0.8916 - val_loss: 0.3598\n",
            "Epoch 48/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7725 - loss: 0.6213\n",
            "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7725 - loss: 0.6211 - val_accuracy: 0.8907 - val_loss: 0.3622\n",
            "Epoch 49/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.6056\n",
            "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.6042 - val_accuracy: 0.8970 - val_loss: 0.3563\n",
            "Epoch 50/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.6031\n",
            "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.6038 - val_accuracy: 0.8943 - val_loss: 0.3530\n",
            "Epoch 51/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.5644\n",
            "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.5652 - val_accuracy: 0.8934 - val_loss: 0.3581\n",
            "Epoch 52/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.6127 \n",
            "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7823 - loss: 0.6112 - val_accuracy: 0.8938 - val_loss: 0.3472\n",
            "Epoch 53/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.6137 \n",
            "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.6040 - val_accuracy: 0.8988 - val_loss: 0.3467\n",
            "Epoch 54/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7821 - loss: 0.6168 \n",
            "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 0.6140 - val_accuracy: 0.8920 - val_loss: 0.3501\n",
            "Epoch 55/1000\n",
            "\u001b[1m44/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: 0.6013\n",
            "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7878 - loss: 0.5989 - val_accuracy: 0.8975 - val_loss: 0.3460\n",
            "Epoch 56/1000\n",
            "\u001b[1m25/52\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.5994 \n",
            "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.5943 - val_accuracy: 0.8947 - val_loss: 0.3425\n",
            "Epoch 57/1000\n",
            "\u001b[1m25/52\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7890 - loss: 0.5865 \n",
            "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.5870 - val_accuracy: 0.9025 - val_loss: 0.3410\n",
            "Epoch 58/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7934 - loss: 0.5835 \n",
            "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7902 - loss: 0.5875 - val_accuracy: 0.9074 - val_loss: 0.3360\n",
            "Epoch 59/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7822 - loss: 0.6115 \n",
            "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.6011 - val_accuracy: 0.9043 - val_loss: 0.3381\n",
            "Epoch 60/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.5752\n",
            "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.5752 - val_accuracy: 0.9011 - val_loss: 0.3352\n",
            "Epoch 61/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7663 - loss: 0.6589 \n",
            "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.6331 - val_accuracy: 0.9088 - val_loss: 0.3298\n",
            "Epoch 62/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.5908 \n",
            "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.5882 - val_accuracy: 0.9025 - val_loss: 0.3274\n",
            "Epoch 63/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.5464 \n",
            "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.5595 - val_accuracy: 0.9088 - val_loss: 0.3259\n",
            "Epoch 64/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7976 - loss: 0.5636 \n",
            "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.5691 - val_accuracy: 0.9097 - val_loss: 0.3231\n",
            "Epoch 65/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.5780 \n",
            "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.5790 - val_accuracy: 0.9083 - val_loss: 0.3261\n",
            "Epoch 66/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.5450 \n",
            "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.5568 - val_accuracy: 0.9129 - val_loss: 0.3199\n",
            "Epoch 67/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7874 - loss: 0.5767\n",
            "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7877 - loss: 0.5755 - val_accuracy: 0.9097 - val_loss: 0.3188\n",
            "Epoch 68/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: 0.5737 \n",
            "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.5783 - val_accuracy: 0.9115 - val_loss: 0.3189\n",
            "Epoch 69/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7794 - loss: 0.5732 \n",
            "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.5680 - val_accuracy: 0.9102 - val_loss: 0.3174\n",
            "Epoch 70/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.5784\n",
            "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.5772 - val_accuracy: 0.9056 - val_loss: 0.3192\n",
            "Epoch 71/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.5664\n",
            "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.5653 - val_accuracy: 0.9120 - val_loss: 0.3128\n",
            "Epoch 72/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.5752 \n",
            "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.5782 - val_accuracy: 0.9156 - val_loss: 0.3146\n",
            "Epoch 73/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.5707\n",
            "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.5667 - val_accuracy: 0.9133 - val_loss: 0.3157\n",
            "Epoch 74/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.5662 \n",
            "Epoch 74: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7929 - loss: 0.5734 - val_accuracy: 0.9142 - val_loss: 0.3114\n",
            "Epoch 75/1000\n",
            "\u001b[1m38/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.5533\n",
            "Epoch 75: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.5539 - val_accuracy: 0.9192 - val_loss: 0.3073\n",
            "Epoch 76/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.5287\n",
            "Epoch 76: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.5291 - val_accuracy: 0.9156 - val_loss: 0.3035\n",
            "Epoch 77/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7932 - loss: 0.5910 \n",
            "Epoch 77: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.5869 - val_accuracy: 0.9156 - val_loss: 0.3065\n",
            "Epoch 78/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.5589\n",
            "Epoch 78: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.5593 - val_accuracy: 0.9129 - val_loss: 0.3090\n",
            "Epoch 79/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7994 - loss: 0.5530\n",
            "Epoch 79: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.5530 - val_accuracy: 0.9165 - val_loss: 0.3080\n",
            "Epoch 80/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.5494 \n",
            "Epoch 80: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.5492 - val_accuracy: 0.9192 - val_loss: 0.2991\n",
            "Epoch 81/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7974 - loss: 0.5662\n",
            "Epoch 81: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.5663 - val_accuracy: 0.9211 - val_loss: 0.2990\n",
            "Epoch 82/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.5687\n",
            "Epoch 82: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.5685 - val_accuracy: 0.9183 - val_loss: 0.3029\n",
            "Epoch 83/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: 0.5871\n",
            "Epoch 83: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.5866 - val_accuracy: 0.9201 - val_loss: 0.3066\n",
            "Epoch 84/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.5476 \n",
            "Epoch 84: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.5552 - val_accuracy: 0.9174 - val_loss: 0.3064\n",
            "Epoch 85/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.5648 \n",
            "Epoch 85: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.5601 - val_accuracy: 0.9170 - val_loss: 0.3040\n",
            "Epoch 86/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.5291 \n",
            "Epoch 86: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8058 - loss: 0.5400 - val_accuracy: 0.9188 - val_loss: 0.3004\n",
            "Epoch 87/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7915 - loss: 0.5512 \n",
            "Epoch 87: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.5506 - val_accuracy: 0.9197 - val_loss: 0.3017\n",
            "Epoch 88/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7893 - loss: 0.5980 \n",
            "Epoch 88: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.5840 - val_accuracy: 0.9197 - val_loss: 0.2990\n",
            "Epoch 89/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.5599 \n",
            "Epoch 89: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.5603 - val_accuracy: 0.9201 - val_loss: 0.2982\n",
            "Epoch 90/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.5514\n",
            "Epoch 90: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.5512 - val_accuracy: 0.9197 - val_loss: 0.2943\n",
            "Epoch 91/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.5329\n",
            "Epoch 91: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.5348 - val_accuracy: 0.9270 - val_loss: 0.2851\n",
            "Epoch 92/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.5432\n",
            "Epoch 92: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.5436 - val_accuracy: 0.9229 - val_loss: 0.2929\n",
            "Epoch 93/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8090 - loss: 0.5378\n",
            "Epoch 93: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.5398 - val_accuracy: 0.9211 - val_loss: 0.2965\n",
            "Epoch 94/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.5418\n",
            "Epoch 94: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.5421 - val_accuracy: 0.9242 - val_loss: 0.2898\n",
            "Epoch 95/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.5462\n",
            "Epoch 95: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.5464 - val_accuracy: 0.9283 - val_loss: 0.2868\n",
            "Epoch 96/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.5238\n",
            "Epoch 96: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8209 - loss: 0.5251 - val_accuracy: 0.9270 - val_loss: 0.2914\n",
            "Epoch 97/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.5308\n",
            "Epoch 97: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.5315 - val_accuracy: 0.9288 - val_loss: 0.2844\n",
            "Epoch 98/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.5419\n",
            "Epoch 98: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.5420 - val_accuracy: 0.9279 - val_loss: 0.2897\n",
            "Epoch 99/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.5665\n",
            "Epoch 99: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8034 - loss: 0.5648 - val_accuracy: 0.9247 - val_loss: 0.2891\n",
            "Epoch 100/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8082 - loss: 0.5384\n",
            "Epoch 100: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.5388 - val_accuracy: 0.9247 - val_loss: 0.2828\n",
            "Epoch 101/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.5372\n",
            "Epoch 101: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.5375 - val_accuracy: 0.9288 - val_loss: 0.2800\n",
            "Epoch 102/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.5331\n",
            "Epoch 102: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.5344 - val_accuracy: 0.9292 - val_loss: 0.2839\n",
            "Epoch 103/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.5488\n",
            "Epoch 103: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.5485 - val_accuracy: 0.9274 - val_loss: 0.2784\n",
            "Epoch 104/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8069 - loss: 0.5272 \n",
            "Epoch 104: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8085 - loss: 0.5234 - val_accuracy: 0.9297 - val_loss: 0.2751\n",
            "Epoch 105/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.5522\n",
            "Epoch 105: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.5516 - val_accuracy: 0.9270 - val_loss: 0.2809\n",
            "Epoch 106/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.5448\n",
            "Epoch 106: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8039 - loss: 0.5443 - val_accuracy: 0.9265 - val_loss: 0.2797\n",
            "Epoch 107/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.5350\n",
            "Epoch 107: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 0.5349 - val_accuracy: 0.9301 - val_loss: 0.2725\n",
            "Epoch 108/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.5220\n",
            "Epoch 108: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8130 - loss: 0.5229 - val_accuracy: 0.9288 - val_loss: 0.2744\n",
            "Epoch 109/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.5605 \n",
            "Epoch 109: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.5500 - val_accuracy: 0.9265 - val_loss: 0.2818\n",
            "Epoch 110/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.5304 \n",
            "Epoch 110: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8156 - loss: 0.5321 - val_accuracy: 0.9315 - val_loss: 0.2707\n",
            "Epoch 111/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.5072\n",
            "Epoch 111: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.5086 - val_accuracy: 0.9310 - val_loss: 0.2707\n",
            "Epoch 112/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.5246\n",
            "Epoch 112: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.5245 - val_accuracy: 0.9251 - val_loss: 0.2779\n",
            "Epoch 113/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.5430\n",
            "Epoch 113: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.5421 - val_accuracy: 0.9265 - val_loss: 0.2758\n",
            "Epoch 114/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.5447\n",
            "Epoch 114: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.5439 - val_accuracy: 0.9279 - val_loss: 0.2724\n",
            "Epoch 115/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.5447 \n",
            "Epoch 115: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8128 - loss: 0.5396 - val_accuracy: 0.9279 - val_loss: 0.2675\n",
            "Epoch 116/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.4812 \n",
            "Epoch 116: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8265 - loss: 0.4952 - val_accuracy: 0.9288 - val_loss: 0.2659\n",
            "Epoch 117/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.5351\n",
            "Epoch 117: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.5352 - val_accuracy: 0.9328 - val_loss: 0.2729\n",
            "Epoch 118/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.5381\n",
            "Epoch 118: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.5383 - val_accuracy: 0.9310 - val_loss: 0.2646\n",
            "Epoch 119/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.5262 \n",
            "Epoch 119: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.5259 - val_accuracy: 0.9315 - val_loss: 0.2683\n",
            "Epoch 120/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.5293\n",
            "Epoch 120: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.5297 - val_accuracy: 0.9310 - val_loss: 0.2640\n",
            "Epoch 121/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.5139\n",
            "Epoch 121: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.5148 - val_accuracy: 0.9310 - val_loss: 0.2639\n",
            "Epoch 122/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.5001 \n",
            "Epoch 122: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.5101 - val_accuracy: 0.9292 - val_loss: 0.2661\n",
            "Epoch 123/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.5141\n",
            "Epoch 123: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8189 - loss: 0.5141 - val_accuracy: 0.9310 - val_loss: 0.2582\n",
            "Epoch 124/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.5277\n",
            "Epoch 124: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.5277 - val_accuracy: 0.9356 - val_loss: 0.2567\n",
            "Epoch 125/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.5393\n",
            "Epoch 125: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.5390 - val_accuracy: 0.9315 - val_loss: 0.2614\n",
            "Epoch 126/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.5214 \n",
            "Epoch 126: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.5240 - val_accuracy: 0.9328 - val_loss: 0.2590\n",
            "Epoch 127/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.5158 \n",
            "Epoch 127: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8141 - loss: 0.5223 - val_accuracy: 0.9315 - val_loss: 0.2669\n",
            "Epoch 128/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8184 - loss: 0.5218\n",
            "Epoch 128: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.5281 - val_accuracy: 0.9319 - val_loss: 0.2623\n",
            "Epoch 129/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.5086\n",
            "Epoch 129: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8210 - loss: 0.5097 - val_accuracy: 0.9347 - val_loss: 0.2584\n",
            "Epoch 130/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.5062 \n",
            "Epoch 130: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.5099 - val_accuracy: 0.9356 - val_loss: 0.2567\n",
            "Epoch 131/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.5383 \n",
            "Epoch 131: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.5365 - val_accuracy: 0.9328 - val_loss: 0.2593\n",
            "Epoch 132/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.5848 \n",
            "Epoch 132: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.5704 - val_accuracy: 0.9324 - val_loss: 0.2608\n",
            "Epoch 133/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.5256\n",
            "Epoch 133: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 0.5258 - val_accuracy: 0.9360 - val_loss: 0.2520\n",
            "Epoch 134/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4769 \n",
            "Epoch 134: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.4967 - val_accuracy: 0.9387 - val_loss: 0.2507\n",
            "Epoch 135/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.5300\n",
            "Epoch 135: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.5303 - val_accuracy: 0.9342 - val_loss: 0.2582\n",
            "Epoch 136/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.5032 \n",
            "Epoch 136: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8202 - loss: 0.5116 - val_accuracy: 0.9369 - val_loss: 0.2557\n",
            "Epoch 137/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.5053\n",
            "Epoch 137: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.5055 - val_accuracy: 0.9288 - val_loss: 0.2592\n",
            "Epoch 138/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.5046\n",
            "Epoch 138: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.5048 - val_accuracy: 0.9365 - val_loss: 0.2462\n",
            "Epoch 139/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.4973 \n",
            "Epoch 139: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.5041 - val_accuracy: 0.9328 - val_loss: 0.2545\n",
            "Epoch 140/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.5149\n",
            "Epoch 140: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8216 - loss: 0.5162 - val_accuracy: 0.9365 - val_loss: 0.2473\n",
            "Epoch 141/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.5364\n",
            "Epoch 141: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.5361 - val_accuracy: 0.9356 - val_loss: 0.2531\n",
            "Epoch 142/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.5085 \n",
            "Epoch 142: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.5091 - val_accuracy: 0.9374 - val_loss: 0.2466\n",
            "Epoch 143/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.5075 \n",
            "Epoch 143: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.5187 - val_accuracy: 0.9347 - val_loss: 0.2496\n",
            "Epoch 144/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.5202\n",
            "Epoch 144: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.5201 - val_accuracy: 0.9324 - val_loss: 0.2513\n",
            "Epoch 145/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.5236 \n",
            "Epoch 145: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8171 - loss: 0.5220 - val_accuracy: 0.9351 - val_loss: 0.2479\n",
            "Epoch 146/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.5064\n",
            "Epoch 146: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8200 - loss: 0.5066 - val_accuracy: 0.9347 - val_loss: 0.2532\n",
            "Epoch 147/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.5089\n",
            "Epoch 147: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.5092 - val_accuracy: 0.9328 - val_loss: 0.2546\n",
            "Epoch 148/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.5158\n",
            "Epoch 148: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.5159 - val_accuracy: 0.9338 - val_loss: 0.2438\n",
            "Epoch 149/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.4954\n",
            "Epoch 149: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.4962 - val_accuracy: 0.9338 - val_loss: 0.2475\n",
            "Epoch 150/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.5325\n",
            "Epoch 150: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8193 - loss: 0.5325 - val_accuracy: 0.9347 - val_loss: 0.2512\n",
            "Epoch 151/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.5396\n",
            "Epoch 151: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.5384 - val_accuracy: 0.9401 - val_loss: 0.2472\n",
            "Epoch 152/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.5303 \n",
            "Epoch 152: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8198 - loss: 0.5260 - val_accuracy: 0.9369 - val_loss: 0.2468\n",
            "Epoch 153/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.5230 \n",
            "Epoch 153: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8234 - loss: 0.5135 - val_accuracy: 0.9406 - val_loss: 0.2386\n",
            "Epoch 154/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.5183\n",
            "Epoch 154: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8185 - loss: 0.5186 - val_accuracy: 0.9347 - val_loss: 0.2465\n",
            "Epoch 155/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.5219\n",
            "Epoch 155: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8170 - loss: 0.5219 - val_accuracy: 0.9356 - val_loss: 0.2473\n",
            "Epoch 156/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8182 - loss: 0.5112\n",
            "Epoch 156: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8183 - loss: 0.5114 - val_accuracy: 0.9356 - val_loss: 0.2472\n",
            "Epoch 157/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.5226\n",
            "Epoch 157: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.5205 - val_accuracy: 0.9365 - val_loss: 0.2466\n",
            "Epoch 158/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.5011\n",
            "Epoch 158: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8302 - loss: 0.5028 - val_accuracy: 0.9406 - val_loss: 0.2426\n",
            "Epoch 159/1000\n",
            "\u001b[1m44/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8064 - loss: 0.5332\n",
            "Epoch 159: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.5314 - val_accuracy: 0.9383 - val_loss: 0.2455\n",
            "Epoch 160/1000\n",
            "\u001b[1m44/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.5176\n",
            "Epoch 160: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.5165 - val_accuracy: 0.9369 - val_loss: 0.2401\n",
            "Epoch 161/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4977\n",
            "Epoch 161: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.4991 - val_accuracy: 0.9360 - val_loss: 0.2442\n",
            "Epoch 162/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8150 - loss: 0.5258\n",
            "Epoch 162: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.5254 - val_accuracy: 0.9383 - val_loss: 0.2423\n",
            "Epoch 163/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.5298\n",
            "Epoch 163: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 0.5280 - val_accuracy: 0.9369 - val_loss: 0.2489\n",
            "Epoch 164/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.5024\n",
            "Epoch 164: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.5031 - val_accuracy: 0.9387 - val_loss: 0.2466\n",
            "Epoch 165/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.5298\n",
            "Epoch 165: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.5287 - val_accuracy: 0.9369 - val_loss: 0.2437\n",
            "Epoch 166/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.5029 \n",
            "Epoch 166: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.5002 - val_accuracy: 0.9401 - val_loss: 0.2381\n",
            "Epoch 167/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.5186\n",
            "Epoch 167: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.5164 - val_accuracy: 0.9410 - val_loss: 0.2423\n",
            "Epoch 168/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.4716\n",
            "Epoch 168: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.4720 - val_accuracy: 0.9428 - val_loss: 0.2370\n",
            "Epoch 169/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.5051 \n",
            "Epoch 169: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8232 - loss: 0.5033 - val_accuracy: 0.9410 - val_loss: 0.2420\n",
            "Epoch 170/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.5119\n",
            "Epoch 170: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.5118 - val_accuracy: 0.9428 - val_loss: 0.2414\n",
            "Epoch 171/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.5364\n",
            "Epoch 171: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8186 - loss: 0.5348 - val_accuracy: 0.9415 - val_loss: 0.2381\n",
            "Epoch 172/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.5394 \n",
            "Epoch 172: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.5291 - val_accuracy: 0.9410 - val_loss: 0.2413\n",
            "Epoch 173/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4994\n",
            "Epoch 173: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8348 - loss: 0.4997 - val_accuracy: 0.9369 - val_loss: 0.2429\n",
            "Epoch 174/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.5269\n",
            "Epoch 174: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8126 - loss: 0.5237 - val_accuracy: 0.9392 - val_loss: 0.2409\n",
            "Epoch 175/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.5059\n",
            "Epoch 175: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.5066 - val_accuracy: 0.9397 - val_loss: 0.2405\n",
            "Epoch 176/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.5132\n",
            "Epoch 176: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.5121 - val_accuracy: 0.9369 - val_loss: 0.2424\n",
            "Epoch 177/1000\n",
            "\u001b[1m38/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8214 - loss: 0.5152\n",
            "Epoch 177: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.5171 - val_accuracy: 0.9392 - val_loss: 0.2449\n",
            "Epoch 178/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8136 - loss: 0.5143 \n",
            "Epoch 178: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.5165 - val_accuracy: 0.9428 - val_loss: 0.2353\n",
            "Epoch 179/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.5258\n",
            "Epoch 179: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.5244 - val_accuracy: 0.9410 - val_loss: 0.2398\n",
            "Epoch 180/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.5282\n",
            "Epoch 180: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.5279 - val_accuracy: 0.9392 - val_loss: 0.2432\n",
            "Epoch 181/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.4934 \n",
            "Epoch 181: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.5053 - val_accuracy: 0.9401 - val_loss: 0.2410\n",
            "Epoch 182/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.5262\n",
            "Epoch 182: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8230 - loss: 0.5256 - val_accuracy: 0.9387 - val_loss: 0.2456\n",
            "Epoch 183/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.4887 \n",
            "Epoch 183: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.4962 - val_accuracy: 0.9378 - val_loss: 0.2420\n",
            "Epoch 184/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4866 \n",
            "Epoch 184: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.4917 - val_accuracy: 0.9397 - val_loss: 0.2382\n",
            "Epoch 185/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.5175\n",
            "Epoch 185: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.5174 - val_accuracy: 0.9428 - val_loss: 0.2375\n",
            "Epoch 186/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.5321 \n",
            "Epoch 186: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8164 - loss: 0.5238 - val_accuracy: 0.9333 - val_loss: 0.2413\n",
            "Epoch 187/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.5168 \n",
            "Epoch 187: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.5205 - val_accuracy: 0.9360 - val_loss: 0.2453\n",
            "Epoch 188/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.5296 \n",
            "Epoch 188: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.5242 - val_accuracy: 0.9297 - val_loss: 0.2512\n",
            "Epoch 189/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.5000\n",
            "Epoch 189: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8339 - loss: 0.5003 - val_accuracy: 0.9392 - val_loss: 0.2382\n",
            "Epoch 190/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.4953 \n",
            "Epoch 190: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.5013 - val_accuracy: 0.9342 - val_loss: 0.2487\n",
            "Epoch 191/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.5106 \n",
            "Epoch 191: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.5063 - val_accuracy: 0.9338 - val_loss: 0.2417\n",
            "Epoch 192/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.5228\n",
            "Epoch 192: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8181 - loss: 0.5199 - val_accuracy: 0.9374 - val_loss: 0.2370\n",
            "Epoch 193/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.5137\n",
            "Epoch 193: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.5136 - val_accuracy: 0.9342 - val_loss: 0.2428\n",
            "Epoch 194/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.5224\n",
            "Epoch 194: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8228 - loss: 0.5222 - val_accuracy: 0.9401 - val_loss: 0.2375\n",
            "Epoch 195/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.5223 \n",
            "Epoch 195: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8286 - loss: 0.5102 - val_accuracy: 0.9401 - val_loss: 0.2385\n",
            "Epoch 196/1000\n",
            "\u001b[1m23/52\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.5354 \n",
            "Epoch 196: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8218 - loss: 0.5248 - val_accuracy: 0.9378 - val_loss: 0.2381\n",
            "Epoch 197/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.4996 \n",
            "Epoch 197: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.4997 - val_accuracy: 0.9397 - val_loss: 0.2378\n",
            "Epoch 198/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.4846\n",
            "Epoch 198: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8316 - loss: 0.4860 - val_accuracy: 0.9374 - val_loss: 0.2366\n",
            "Epoch 198: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc73c08e210>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.2378 \n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "[2.6675340e-02 1.4490572e-01 8.2818639e-01 2.2731087e-04 3.8110066e-09\n",
            " 5.1926777e-06 3.2639856e-18]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.93       410\n",
            "           1       0.96      0.82      0.89       380\n",
            "           2       0.92      0.94      0.93       325\n",
            "           3       0.90      0.96      0.93        83\n",
            "           4       0.92      0.99      0.95       136\n",
            "           5       0.87      0.99      0.92       324\n",
            "           6       0.96      1.00      0.98       546\n",
            "\n",
            "    accuracy                           0.94      2204\n",
            "   macro avg       0.93      0.94      0.93      2204\n",
            "weighted avg       0.94      0.94      0.94      2204\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpa5lt47vc/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpa5lt47vc/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpa5lt47vc'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 7), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136091977813840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136091977815376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136091977815184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136091977824976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136091977815952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136091977824208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1744955306.135611   34857 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1744955306.135636   34857 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2025-04-18 12:48:26.135965: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpa5lt47vc\n",
            "2025-04-18 12:48:26.136551: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-04-18 12:48:26.136560: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpa5lt47vc\n",
            "I0000 00:00:1744955306.140748   34857 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
            "2025-04-18 12:48:26.141440: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-04-18 12:48:26.161567: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpa5lt47vc\n",
            "2025-04-18 12:48:26.167857: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 31897 microseconds.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6688"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/01DB783D25219E60/HOMEWORK/TGMT/ThiGiacPC/.venv/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 420 μs, total: 420 μs\n",
            "Wall time: 305 μs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.6675289e-02 1.4490569e-01 8.2818645e-01 2.2731151e-04 3.8109991e-09\n",
            " 5.1926681e-06 3.2639732e-18]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
