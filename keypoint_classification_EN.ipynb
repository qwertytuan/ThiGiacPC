{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-15 09:01:46.109154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744682506.145013   79634 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744682506.156521   79634 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1744682506.183996   79634 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744682506.184034   79634 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744682506.184038   79634 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744682506.184041   79634 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-15 09:01:46.192659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
        "model_save_path = 'model/keypoint_classifier/keypoint_classifier.keras'\n",
        "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1744682513.101363   79634 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m860\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m77\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,147</span> (4.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,147\u001b[0m (4.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,147</span> (4.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,147\u001b[0m (4.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2592 - loss: 1.8891 \n",
            "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3007 - loss: 1.8509 - val_accuracy: 0.5036 - val_loss: 1.5615\n",
            "Epoch 2/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4889 - loss: 1.5638 \n",
            "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4895 - loss: 1.5465 - val_accuracy: 0.5386 - val_loss: 1.3103\n",
            "Epoch 3/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4969 - loss: 1.3976 \n",
            "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5018 - loss: 1.3833 - val_accuracy: 0.5889 - val_loss: 1.1570\n",
            "Epoch 4/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5212 - loss: 1.2881 \n",
            "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5250 - loss: 1.2780 - val_accuracy: 0.6098 - val_loss: 1.0601\n",
            "Epoch 5/1000\n",
            "\u001b[1m38/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5564 - loss: 1.1806 \n",
            "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5576 - loss: 1.1765 - val_accuracy: 0.6397 - val_loss: 0.9835\n",
            "Epoch 6/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5741 - loss: 1.1060 \n",
            "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5748 - loss: 1.1042 - val_accuracy: 0.6579 - val_loss: 0.9181\n",
            "Epoch 7/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 1.0747 \n",
            "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 1.0707 - val_accuracy: 0.7314 - val_loss: 0.8494\n",
            "Epoch 8/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6134 - loss: 1.0035 \n",
            "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6142 - loss: 1.0008 - val_accuracy: 0.7713 - val_loss: 0.7868\n",
            "Epoch 9/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6293 - loss: 0.9446 \n",
            "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6264 - loss: 0.9521 - val_accuracy: 0.7754 - val_loss: 0.7360\n",
            "Epoch 10/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6492 - loss: 0.9201 \n",
            "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6496 - loss: 0.9169 - val_accuracy: 0.7899 - val_loss: 0.6921\n",
            "Epoch 11/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6577 - loss: 0.9066 \n",
            "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6577 - loss: 0.9039 - val_accuracy: 0.8108 - val_loss: 0.6608\n",
            "Epoch 12/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6498 - loss: 0.8796 \n",
            "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6554 - loss: 0.8740 - val_accuracy: 0.8190 - val_loss: 0.6279\n",
            "Epoch 13/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6673 - loss: 0.8605 \n",
            "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6688 - loss: 0.8561 - val_accuracy: 0.8203 - val_loss: 0.6003\n",
            "Epoch 14/1000\n",
            "\u001b[1m38/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6775 - loss: 0.8242 \n",
            "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6778 - loss: 0.8241 - val_accuracy: 0.8339 - val_loss: 0.5777\n",
            "Epoch 15/1000\n",
            "\u001b[1m36/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6823 - loss: 0.8446 \n",
            "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.8366 - val_accuracy: 0.8480 - val_loss: 0.5637\n",
            "Epoch 16/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6940 - loss: 0.7938 \n",
            "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6948 - loss: 0.7909 - val_accuracy: 0.8539 - val_loss: 0.5431\n",
            "Epoch 17/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7067 - loss: 0.7416 \n",
            "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7071 - loss: 0.7450 - val_accuracy: 0.8652 - val_loss: 0.5275\n",
            "Epoch 18/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6998 - loss: 0.7781 \n",
            "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7004 - loss: 0.7766 - val_accuracy: 0.8730 - val_loss: 0.5169\n",
            "Epoch 19/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.7391 \n",
            "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7191 - loss: 0.7442 - val_accuracy: 0.8748 - val_loss: 0.4994\n",
            "Epoch 20/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.7081 \n",
            "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7232 - loss: 0.7163 - val_accuracy: 0.8770 - val_loss: 0.4915\n",
            "Epoch 21/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.7433 \n",
            "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.7412 - val_accuracy: 0.8779 - val_loss: 0.4806\n",
            "Epoch 22/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7257 - loss: 0.7255 \n",
            "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.7210 - val_accuracy: 0.8866 - val_loss: 0.4630\n",
            "Epoch 23/1000\n",
            "\u001b[1m36/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7245 - loss: 0.7137 \n",
            "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.7134 - val_accuracy: 0.8825 - val_loss: 0.4555\n",
            "Epoch 24/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.7038 \n",
            "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7342 - loss: 0.7066 - val_accuracy: 0.8766 - val_loss: 0.4476\n",
            "Epoch 25/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.6813 \n",
            "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.6789 - val_accuracy: 0.8929 - val_loss: 0.4343\n",
            "Epoch 26/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.7110 \n",
            "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.6994 - val_accuracy: 0.8938 - val_loss: 0.4249\n",
            "Epoch 27/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7382 - loss: 0.6906 \n",
            "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.6856 - val_accuracy: 0.8911 - val_loss: 0.4222\n",
            "Epoch 28/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7482 - loss: 0.6708 \n",
            "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7482 - loss: 0.6733 - val_accuracy: 0.8979 - val_loss: 0.4224\n",
            "Epoch 29/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.6654 \n",
            "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.6639 - val_accuracy: 0.8993 - val_loss: 0.4122\n",
            "Epoch 30/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7571 - loss: 0.6525 \n",
            "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.6523 - val_accuracy: 0.8943 - val_loss: 0.3978\n",
            "Epoch 31/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.6551 \n",
            "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.6548 - val_accuracy: 0.9047 - val_loss: 0.3975\n",
            "Epoch 32/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7493 - loss: 0.6390 \n",
            "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7495 - loss: 0.6460 - val_accuracy: 0.8997 - val_loss: 0.3970\n",
            "Epoch 33/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.6465 \n",
            "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.6525 - val_accuracy: 0.8997 - val_loss: 0.3925\n",
            "Epoch 34/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7505 - loss: 0.6542 \n",
            "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7544 - loss: 0.6491 - val_accuracy: 0.9056 - val_loss: 0.3845\n",
            "Epoch 35/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.6024 \n",
            "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.6135 - val_accuracy: 0.9043 - val_loss: 0.3811\n",
            "Epoch 36/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7828 - loss: 0.6017 \n",
            "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7771 - loss: 0.6126 - val_accuracy: 0.9065 - val_loss: 0.3744\n",
            "Epoch 37/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.6366 \n",
            "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.6339 - val_accuracy: 0.9038 - val_loss: 0.3698\n",
            "Epoch 38/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7596 - loss: 0.6388 \n",
            "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.6335 - val_accuracy: 0.9070 - val_loss: 0.3678\n",
            "Epoch 39/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 0.5949 \n",
            "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.6009 - val_accuracy: 0.9029 - val_loss: 0.3644\n",
            "Epoch 40/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7616 - loss: 0.6453 \n",
            "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7630 - loss: 0.6415 - val_accuracy: 0.9065 - val_loss: 0.3587\n",
            "Epoch 41/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7634 - loss: 0.6272 \n",
            "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.6253 - val_accuracy: 0.9056 - val_loss: 0.3539\n",
            "Epoch 42/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7651 - loss: 0.6141 \n",
            "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.6166 - val_accuracy: 0.9074 - val_loss: 0.3624\n",
            "Epoch 43/1000\n",
            "\u001b[1m36/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7793 - loss: 0.6012 \n",
            "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.6010 - val_accuracy: 0.9097 - val_loss: 0.3534\n",
            "Epoch 44/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.6091 \n",
            "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.6109 - val_accuracy: 0.9093 - val_loss: 0.3529\n",
            "Epoch 45/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.5822 \n",
            "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.5949 - val_accuracy: 0.9111 - val_loss: 0.3447\n",
            "Epoch 46/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.6049 \n",
            "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.6031 - val_accuracy: 0.9120 - val_loss: 0.3452\n",
            "Epoch 47/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.5799 \n",
            "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.5893 - val_accuracy: 0.9147 - val_loss: 0.3442\n",
            "Epoch 48/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.6010\n",
            "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.6009 - val_accuracy: 0.9147 - val_loss: 0.3414\n",
            "Epoch 49/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7753 - loss: 0.6238 \n",
            "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.6167 - val_accuracy: 0.9165 - val_loss: 0.3368\n",
            "Epoch 50/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: 0.5857 \n",
            "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5918 - val_accuracy: 0.9174 - val_loss: 0.3366\n",
            "Epoch 51/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7840 - loss: 0.5939 \n",
            "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.5898 - val_accuracy: 0.9156 - val_loss: 0.3354\n",
            "Epoch 52/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7993 - loss: 0.5535 \n",
            "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.5603 - val_accuracy: 0.9124 - val_loss: 0.3306\n",
            "Epoch 53/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.5949 \n",
            "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7836 - loss: 0.5929 - val_accuracy: 0.9174 - val_loss: 0.3264\n",
            "Epoch 54/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7970 - loss: 0.5670 \n",
            "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.5755 - val_accuracy: 0.9133 - val_loss: 0.3302\n",
            "Epoch 55/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.5713 \n",
            "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5738 - val_accuracy: 0.9201 - val_loss: 0.3242\n",
            "Epoch 56/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7809 - loss: 0.5941 \n",
            "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.5886 - val_accuracy: 0.9211 - val_loss: 0.3271\n",
            "Epoch 57/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7816 - loss: 0.5885 \n",
            "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.5851 - val_accuracy: 0.9224 - val_loss: 0.3148\n",
            "Epoch 58/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.5786 \n",
            "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.5815 - val_accuracy: 0.9156 - val_loss: 0.3276\n",
            "Epoch 59/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.5991 \n",
            "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7799 - loss: 0.5918 - val_accuracy: 0.9183 - val_loss: 0.3231\n",
            "Epoch 60/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.5625\n",
            "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.5630 - val_accuracy: 0.9215 - val_loss: 0.3210\n",
            "Epoch 61/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8096 - loss: 0.5522 \n",
            "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.5581 - val_accuracy: 0.9165 - val_loss: 0.3210\n",
            "Epoch 62/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.5464 \n",
            "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.5516 - val_accuracy: 0.9179 - val_loss: 0.3126\n",
            "Epoch 63/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.5871 \n",
            "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.5867 - val_accuracy: 0.9183 - val_loss: 0.3149\n",
            "Epoch 64/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.5563 \n",
            "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.5593 - val_accuracy: 0.9170 - val_loss: 0.3167\n",
            "Epoch 65/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.5368 \n",
            "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.5364 - val_accuracy: 0.9179 - val_loss: 0.3138\n",
            "Epoch 66/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.5552 \n",
            "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.5615 - val_accuracy: 0.9201 - val_loss: 0.3151\n",
            "Epoch 67/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7863 - loss: 0.5812 \n",
            "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.5794 - val_accuracy: 0.9201 - val_loss: 0.3170\n",
            "Epoch 68/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.5791 \n",
            "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.5782 - val_accuracy: 0.9238 - val_loss: 0.3140\n",
            "Epoch 69/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.5527\n",
            "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.5538 - val_accuracy: 0.9165 - val_loss: 0.3205\n",
            "Epoch 70/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.5614 \n",
            "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.5653 - val_accuracy: 0.9211 - val_loss: 0.3057\n",
            "Epoch 71/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.5270 \n",
            "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.5367 - val_accuracy: 0.9183 - val_loss: 0.3124\n",
            "Epoch 72/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.5606 \n",
            "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.5611 - val_accuracy: 0.9197 - val_loss: 0.3070\n",
            "Epoch 73/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.5519 \n",
            "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.5578 - val_accuracy: 0.9233 - val_loss: 0.3092\n",
            "Epoch 74/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8019 - loss: 0.5487 \n",
            "Epoch 74: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.5509 - val_accuracy: 0.9188 - val_loss: 0.3108\n",
            "Epoch 75/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.5637 \n",
            "Epoch 75: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.5574 - val_accuracy: 0.9206 - val_loss: 0.3096\n",
            "Epoch 76/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7907 - loss: 0.5618 \n",
            "Epoch 76: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7918 - loss: 0.5658 - val_accuracy: 0.9242 - val_loss: 0.3059\n",
            "Epoch 77/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: 0.5612 \n",
            "Epoch 77: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.5526 - val_accuracy: 0.9220 - val_loss: 0.3047\n",
            "Epoch 78/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.5634 \n",
            "Epoch 78: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.5606 - val_accuracy: 0.9192 - val_loss: 0.3009\n",
            "Epoch 79/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.5704 \n",
            "Epoch 79: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.5657 - val_accuracy: 0.9215 - val_loss: 0.2978\n",
            "Epoch 80/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.5570 \n",
            "Epoch 80: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.5517 - val_accuracy: 0.9238 - val_loss: 0.2926\n",
            "Epoch 81/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7905 - loss: 0.5391 \n",
            "Epoch 81: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.5423 - val_accuracy: 0.9142 - val_loss: 0.3127\n",
            "Epoch 82/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 0.5426 \n",
            "Epoch 82: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5410 - val_accuracy: 0.9233 - val_loss: 0.2948\n",
            "Epoch 83/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.5536 \n",
            "Epoch 83: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7978 - loss: 0.5558 - val_accuracy: 0.9242 - val_loss: 0.3013\n",
            "Epoch 84/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.5276 \n",
            "Epoch 84: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.5354 - val_accuracy: 0.9256 - val_loss: 0.2999\n",
            "Epoch 85/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.5152 \n",
            "Epoch 85: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.5218 - val_accuracy: 0.9283 - val_loss: 0.2927\n",
            "Epoch 86/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.5392 \n",
            "Epoch 86: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.5450 - val_accuracy: 0.9238 - val_loss: 0.2964\n",
            "Epoch 87/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8039 - loss: 0.5743 \n",
            "Epoch 87: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.5640 - val_accuracy: 0.9297 - val_loss: 0.2961\n",
            "Epoch 88/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.5332 \n",
            "Epoch 88: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.5319 - val_accuracy: 0.9256 - val_loss: 0.2922\n",
            "Epoch 89/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.5297 \n",
            "Epoch 89: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8116 - loss: 0.5371 - val_accuracy: 0.9292 - val_loss: 0.2946\n",
            "Epoch 90/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.5761 \n",
            "Epoch 90: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.5695 - val_accuracy: 0.9260 - val_loss: 0.2841\n",
            "Epoch 91/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.5095 \n",
            "Epoch 91: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.5217 - val_accuracy: 0.9192 - val_loss: 0.2938\n",
            "Epoch 92/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.5338 \n",
            "Epoch 92: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.5409 - val_accuracy: 0.9279 - val_loss: 0.2886\n",
            "Epoch 93/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.5056\n",
            "Epoch 93: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.5085 - val_accuracy: 0.9265 - val_loss: 0.2826\n",
            "Epoch 94/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.5200 \n",
            "Epoch 94: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.5289 - val_accuracy: 0.9270 - val_loss: 0.2815\n",
            "Epoch 95/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.5443 \n",
            "Epoch 95: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.5421 - val_accuracy: 0.9242 - val_loss: 0.2906\n",
            "Epoch 96/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.5241 \n",
            "Epoch 96: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.5312 - val_accuracy: 0.9292 - val_loss: 0.2849\n",
            "Epoch 97/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.5329 \n",
            "Epoch 97: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.5345 - val_accuracy: 0.9274 - val_loss: 0.2841\n",
            "Epoch 98/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.5524 \n",
            "Epoch 98: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.5451 - val_accuracy: 0.9333 - val_loss: 0.2822\n",
            "Epoch 99/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.5485 \n",
            "Epoch 99: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.5384 - val_accuracy: 0.9256 - val_loss: 0.2940\n",
            "Epoch 100/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.5405\n",
            "Epoch 100: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.5400 - val_accuracy: 0.9292 - val_loss: 0.2843\n",
            "Epoch 101/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8061 - loss: 0.5231 \n",
            "Epoch 101: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.5253 - val_accuracy: 0.9301 - val_loss: 0.2845\n",
            "Epoch 102/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8067 - loss: 0.5430 \n",
            "Epoch 102: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.5387 - val_accuracy: 0.9342 - val_loss: 0.2732\n",
            "Epoch 103/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8118 - loss: 0.5464 \n",
            "Epoch 103: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.5464 - val_accuracy: 0.9369 - val_loss: 0.2760\n",
            "Epoch 104/1000\n",
            "\u001b[1m38/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8117 - loss: 0.5490 \n",
            "Epoch 104: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.5450 - val_accuracy: 0.9365 - val_loss: 0.2766\n",
            "Epoch 105/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8095 - loss: 0.5321 \n",
            "Epoch 105: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.5314 - val_accuracy: 0.9315 - val_loss: 0.2876\n",
            "Epoch 106/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.5513 \n",
            "Epoch 106: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.5475 - val_accuracy: 0.9365 - val_loss: 0.2869\n",
            "Epoch 107/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.5023 \n",
            "Epoch 107: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.5040 - val_accuracy: 0.9401 - val_loss: 0.2772\n",
            "Epoch 108/1000\n",
            "\u001b[1m36/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8043 - loss: 0.5556 \n",
            "Epoch 108: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8051 - loss: 0.5515 - val_accuracy: 0.9347 - val_loss: 0.2744\n",
            "Epoch 109/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.5197 \n",
            "Epoch 109: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.5211 - val_accuracy: 0.9319 - val_loss: 0.2770\n",
            "Epoch 110/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8091 - loss: 0.5539 \n",
            "Epoch 110: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.5441 - val_accuracy: 0.9333 - val_loss: 0.2725\n",
            "Epoch 111/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.5250 \n",
            "Epoch 111: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8170 - loss: 0.5267 - val_accuracy: 0.9324 - val_loss: 0.2786\n",
            "Epoch 112/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.5612 \n",
            "Epoch 112: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.5532 - val_accuracy: 0.9283 - val_loss: 0.2828\n",
            "Epoch 113/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.5535 \n",
            "Epoch 113: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.5421 - val_accuracy: 0.9288 - val_loss: 0.2814\n",
            "Epoch 114/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.5497 \n",
            "Epoch 114: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.5433 - val_accuracy: 0.9328 - val_loss: 0.2748\n",
            "Epoch 115/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8003 - loss: 0.5485 \n",
            "Epoch 115: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.5403 - val_accuracy: 0.9365 - val_loss: 0.2766\n",
            "Epoch 116/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: 0.5252 \n",
            "Epoch 116: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.5265 - val_accuracy: 0.9347 - val_loss: 0.2809\n",
            "Epoch 117/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.5446 \n",
            "Epoch 117: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.5381 - val_accuracy: 0.9274 - val_loss: 0.2742\n",
            "Epoch 118/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8035 - loss: 0.5575 \n",
            "Epoch 118: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.5490 - val_accuracy: 0.9319 - val_loss: 0.2795\n",
            "Epoch 119/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.5183 \n",
            "Epoch 119: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.5175 - val_accuracy: 0.9415 - val_loss: 0.2690\n",
            "Epoch 120/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.5456 \n",
            "Epoch 120: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.5427 - val_accuracy: 0.9415 - val_loss: 0.2622\n",
            "Epoch 121/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.5127 \n",
            "Epoch 121: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8156 - loss: 0.5178 - val_accuracy: 0.9365 - val_loss: 0.2719\n",
            "Epoch 122/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.5306 \n",
            "Epoch 122: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8156 - loss: 0.5244 - val_accuracy: 0.9356 - val_loss: 0.2667\n",
            "Epoch 123/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.5280 \n",
            "Epoch 123: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8104 - loss: 0.5251 - val_accuracy: 0.9374 - val_loss: 0.2662\n",
            "Epoch 124/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.5358 \n",
            "Epoch 124: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.5353 - val_accuracy: 0.9387 - val_loss: 0.2694\n",
            "Epoch 125/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4997 \n",
            "Epoch 125: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.5032 - val_accuracy: 0.9360 - val_loss: 0.2702\n",
            "Epoch 126/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8159 - loss: 0.5346 \n",
            "Epoch 126: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.5329 - val_accuracy: 0.9306 - val_loss: 0.2779\n",
            "Epoch 127/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.4944 \n",
            "Epoch 127: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.5010 - val_accuracy: 0.9365 - val_loss: 0.2706\n",
            "Epoch 128/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.5285 \n",
            "Epoch 128: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8156 - loss: 0.5258 - val_accuracy: 0.9356 - val_loss: 0.2655\n",
            "Epoch 129/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.5172 \n",
            "Epoch 129: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.5206 - val_accuracy: 0.9238 - val_loss: 0.2752\n",
            "Epoch 130/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.5233 \n",
            "Epoch 130: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.5267 - val_accuracy: 0.9338 - val_loss: 0.2683\n",
            "Epoch 131/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.5169 \n",
            "Epoch 131: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.5174 - val_accuracy: 0.9401 - val_loss: 0.2688\n",
            "Epoch 132/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.5039 \n",
            "Epoch 132: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.5025 - val_accuracy: 0.9401 - val_loss: 0.2639\n",
            "Epoch 133/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.5396 \n",
            "Epoch 133: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.5330 - val_accuracy: 0.9351 - val_loss: 0.2766\n",
            "Epoch 134/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4967 \n",
            "Epoch 134: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.5005 - val_accuracy: 0.9397 - val_loss: 0.2719\n",
            "Epoch 135/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.5222 \n",
            "Epoch 135: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.5185 - val_accuracy: 0.9374 - val_loss: 0.2705\n",
            "Epoch 136/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.4982 \n",
            "Epoch 136: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.5057 - val_accuracy: 0.9342 - val_loss: 0.2705\n",
            "Epoch 137/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.5084 \n",
            "Epoch 137: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8174 - loss: 0.5104 - val_accuracy: 0.9397 - val_loss: 0.2606\n",
            "Epoch 138/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.5078 \n",
            "Epoch 138: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.5057 - val_accuracy: 0.9383 - val_loss: 0.2630\n",
            "Epoch 139/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.4868 \n",
            "Epoch 139: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.4955 - val_accuracy: 0.9265 - val_loss: 0.2707\n",
            "Epoch 140/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.5257 \n",
            "Epoch 140: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.5250 - val_accuracy: 0.9415 - val_loss: 0.2659\n",
            "Epoch 141/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.5360 \n",
            "Epoch 141: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.5339 - val_accuracy: 0.9369 - val_loss: 0.2685\n",
            "Epoch 142/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.5061 \n",
            "Epoch 142: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.5078 - val_accuracy: 0.9392 - val_loss: 0.2611\n",
            "Epoch 143/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8146 - loss: 0.5237 \n",
            "Epoch 143: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8159 - loss: 0.5184 - val_accuracy: 0.9365 - val_loss: 0.2710\n",
            "Epoch 144/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.5096 \n",
            "Epoch 144: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.5140 - val_accuracy: 0.9383 - val_loss: 0.2678\n",
            "Epoch 145/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.5222 \n",
            "Epoch 145: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.5198 - val_accuracy: 0.9392 - val_loss: 0.2699\n",
            "Epoch 146/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8037 - loss: 0.5468 \n",
            "Epoch 146: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.5348 - val_accuracy: 0.9365 - val_loss: 0.2650\n",
            "Epoch 147/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.4859 \n",
            "Epoch 147: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.4840 - val_accuracy: 0.9410 - val_loss: 0.2623\n",
            "Epoch 148/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8096 - loss: 0.5014 \n",
            "Epoch 148: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.5013 - val_accuracy: 0.9360 - val_loss: 0.2600\n",
            "Epoch 149/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.5066 \n",
            "Epoch 149: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8150 - loss: 0.5105 - val_accuracy: 0.9392 - val_loss: 0.2654\n",
            "Epoch 150/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.5157 \n",
            "Epoch 150: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.5147 - val_accuracy: 0.9410 - val_loss: 0.2600\n",
            "Epoch 151/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.4963 \n",
            "Epoch 151: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.4992 - val_accuracy: 0.9347 - val_loss: 0.2693\n",
            "Epoch 152/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.5081 \n",
            "Epoch 152: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.5073 - val_accuracy: 0.9428 - val_loss: 0.2616\n",
            "Epoch 153/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8064 - loss: 0.5374 \n",
            "Epoch 153: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.5369 - val_accuracy: 0.9351 - val_loss: 0.2690\n",
            "Epoch 154/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4902 \n",
            "Epoch 154: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.5004 - val_accuracy: 0.9410 - val_loss: 0.2573\n",
            "Epoch 155/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.5305 \n",
            "Epoch 155: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.5252 - val_accuracy: 0.9401 - val_loss: 0.2555\n",
            "Epoch 156/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.5139 \n",
            "Epoch 156: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.5124 - val_accuracy: 0.9392 - val_loss: 0.2632\n",
            "Epoch 157/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4909 \n",
            "Epoch 157: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.5032 - val_accuracy: 0.9383 - val_loss: 0.2657\n",
            "Epoch 158/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.5052 \n",
            "Epoch 158: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.5036 - val_accuracy: 0.9410 - val_loss: 0.2601\n",
            "Epoch 159/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.5209 \n",
            "Epoch 159: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.5168 - val_accuracy: 0.9347 - val_loss: 0.2615\n",
            "Epoch 160/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.5161 \n",
            "Epoch 160: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.5143 - val_accuracy: 0.9342 - val_loss: 0.2636\n",
            "Epoch 161/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4800 \n",
            "Epoch 161: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8223 - loss: 0.4894 - val_accuracy: 0.9360 - val_loss: 0.2718\n",
            "Epoch 162/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.5124 \n",
            "Epoch 162: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.5090 - val_accuracy: 0.9410 - val_loss: 0.2591\n",
            "Epoch 163/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.4917 \n",
            "Epoch 163: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.5016 - val_accuracy: 0.9387 - val_loss: 0.2611\n",
            "Epoch 164/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.5043 \n",
            "Epoch 164: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.5082 - val_accuracy: 0.9356 - val_loss: 0.2609\n",
            "Epoch 165/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.4841 \n",
            "Epoch 165: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.4891 - val_accuracy: 0.9401 - val_loss: 0.2577\n",
            "Epoch 166/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.5313 \n",
            "Epoch 166: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.5239 - val_accuracy: 0.9406 - val_loss: 0.2592\n",
            "Epoch 167/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.4825 \n",
            "Epoch 167: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.4824 - val_accuracy: 0.9369 - val_loss: 0.2587\n",
            "Epoch 168/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.5248 \n",
            "Epoch 168: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.5187 - val_accuracy: 0.9392 - val_loss: 0.2602\n",
            "Epoch 169/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.5187 \n",
            "Epoch 169: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.5197 - val_accuracy: 0.9319 - val_loss: 0.2698\n",
            "Epoch 170/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.4980 \n",
            "Epoch 170: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.5018 - val_accuracy: 0.9374 - val_loss: 0.2662\n",
            "Epoch 171/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8299 - loss: 0.5001 \n",
            "Epoch 171: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8287 - loss: 0.4988 - val_accuracy: 0.9387 - val_loss: 0.2612\n",
            "Epoch 172/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.5190\n",
            "Epoch 172: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.5183 - val_accuracy: 0.9428 - val_loss: 0.2587\n",
            "Epoch 173/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.5037 \n",
            "Epoch 173: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8214 - loss: 0.5016 - val_accuracy: 0.9338 - val_loss: 0.2692\n",
            "Epoch 174/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.5251 \n",
            "Epoch 174: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.5149 - val_accuracy: 0.9279 - val_loss: 0.2630\n",
            "Epoch 175/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4703 \n",
            "Epoch 175: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.4797 - val_accuracy: 0.9433 - val_loss: 0.2549\n",
            "Epoch 176/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4764 \n",
            "Epoch 176: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.4805 - val_accuracy: 0.9365 - val_loss: 0.2606\n",
            "Epoch 177/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4706 \n",
            "Epoch 177: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.4747 - val_accuracy: 0.9342 - val_loss: 0.2593\n",
            "Epoch 178/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.5073 \n",
            "Epoch 178: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 0.5087 - val_accuracy: 0.9319 - val_loss: 0.2596\n",
            "Epoch 179/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.4780 \n",
            "Epoch 179: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.4859 - val_accuracy: 0.9401 - val_loss: 0.2554\n",
            "Epoch 180/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8263 - loss: 0.4847 \n",
            "Epoch 180: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.4902 - val_accuracy: 0.9342 - val_loss: 0.2615\n",
            "Epoch 181/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.5128 \n",
            "Epoch 181: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.5076 - val_accuracy: 0.9392 - val_loss: 0.2600\n",
            "Epoch 182/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.5214 \n",
            "Epoch 182: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.5179 - val_accuracy: 0.9387 - val_loss: 0.2559\n",
            "Epoch 183/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.5193 \n",
            "Epoch 183: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.5123 - val_accuracy: 0.9392 - val_loss: 0.2554\n",
            "Epoch 184/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.4794 \n",
            "Epoch 184: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4862 - val_accuracy: 0.9397 - val_loss: 0.2540\n",
            "Epoch 185/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4645 \n",
            "Epoch 185: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4748 - val_accuracy: 0.9378 - val_loss: 0.2599\n",
            "Epoch 186/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.5103 \n",
            "Epoch 186: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.5020 - val_accuracy: 0.9369 - val_loss: 0.2564\n",
            "Epoch 187/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.4775 \n",
            "Epoch 187: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.4845 - val_accuracy: 0.9383 - val_loss: 0.2639\n",
            "Epoch 188/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.4932 \n",
            "Epoch 188: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8278 - loss: 0.4936 - val_accuracy: 0.9406 - val_loss: 0.2513\n",
            "Epoch 189/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.4766 \n",
            "Epoch 189: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.4795 - val_accuracy: 0.9387 - val_loss: 0.2584\n",
            "Epoch 190/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4841 \n",
            "Epoch 190: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4860 - val_accuracy: 0.9387 - val_loss: 0.2563\n",
            "Epoch 191/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8312 - loss: 0.4897 \n",
            "Epoch 191: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.4926 - val_accuracy: 0.9442 - val_loss: 0.2439\n",
            "Epoch 192/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.4869 \n",
            "Epoch 192: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.4907 - val_accuracy: 0.9433 - val_loss: 0.2434\n",
            "Epoch 193/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.4961 \n",
            "Epoch 193: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.4972 - val_accuracy: 0.9442 - val_loss: 0.2513\n",
            "Epoch 194/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.4948 \n",
            "Epoch 194: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.4944 - val_accuracy: 0.9360 - val_loss: 0.2576\n",
            "Epoch 195/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.4990 \n",
            "Epoch 195: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.5022 - val_accuracy: 0.9374 - val_loss: 0.2547\n",
            "Epoch 196/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.4669\n",
            "Epoch 196: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8312 - loss: 0.4673 - val_accuracy: 0.9378 - val_loss: 0.2553\n",
            "Epoch 197/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.5317 \n",
            "Epoch 197: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.5255 - val_accuracy: 0.9387 - val_loss: 0.2573\n",
            "Epoch 198/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.5029 \n",
            "Epoch 198: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8249 - loss: 0.4983 - val_accuracy: 0.9487 - val_loss: 0.2405\n",
            "Epoch 199/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.4866 \n",
            "Epoch 199: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.4845 - val_accuracy: 0.9378 - val_loss: 0.2525\n",
            "Epoch 200/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.5126 \n",
            "Epoch 200: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8186 - loss: 0.5114 - val_accuracy: 0.9401 - val_loss: 0.2475\n",
            "Epoch 201/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4996 \n",
            "Epoch 201: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.4964 - val_accuracy: 0.9392 - val_loss: 0.2510\n",
            "Epoch 202/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.4955 \n",
            "Epoch 202: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8278 - loss: 0.4960 - val_accuracy: 0.9378 - val_loss: 0.2541\n",
            "Epoch 203/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.5053 \n",
            "Epoch 203: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.5007 - val_accuracy: 0.9428 - val_loss: 0.2523\n",
            "Epoch 204/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.4770 \n",
            "Epoch 204: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.4797 - val_accuracy: 0.9415 - val_loss: 0.2528\n",
            "Epoch 205/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.4770 \n",
            "Epoch 205: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8326 - loss: 0.4845 - val_accuracy: 0.9428 - val_loss: 0.2441\n",
            "Epoch 206/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.4859 \n",
            "Epoch 206: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.4878 - val_accuracy: 0.9442 - val_loss: 0.2455\n",
            "Epoch 207/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.4959 \n",
            "Epoch 207: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.4954 - val_accuracy: 0.9415 - val_loss: 0.2548\n",
            "Epoch 208/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.4712 \n",
            "Epoch 208: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.4787 - val_accuracy: 0.9410 - val_loss: 0.2568\n",
            "Epoch 209/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.4965 \n",
            "Epoch 209: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.4901 - val_accuracy: 0.9446 - val_loss: 0.2479\n",
            "Epoch 210/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.4883 \n",
            "Epoch 210: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8305 - loss: 0.4922 - val_accuracy: 0.9360 - val_loss: 0.2537\n",
            "Epoch 211/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.4624 \n",
            "Epoch 211: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.4693 - val_accuracy: 0.9406 - val_loss: 0.2498\n",
            "Epoch 212/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8282 - loss: 0.4973 \n",
            "Epoch 212: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.4940 - val_accuracy: 0.9392 - val_loss: 0.2489\n",
            "Epoch 213/1000\n",
            "\u001b[1m36/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.4705 \n",
            "Epoch 213: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8365 - loss: 0.4706 - val_accuracy: 0.9369 - val_loss: 0.2469\n",
            "Epoch 214/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8332 - loss: 0.4874 \n",
            "Epoch 214: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.4884 - val_accuracy: 0.9310 - val_loss: 0.2591\n",
            "Epoch 215/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.4444 \n",
            "Epoch 215: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.4558 - val_accuracy: 0.9365 - val_loss: 0.2507\n",
            "Epoch 216/1000\n",
            "\u001b[1m35/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8218 - loss: 0.5093 \n",
            "Epoch 216: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.5022 - val_accuracy: 0.9419 - val_loss: 0.2493\n",
            "Epoch 217/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.4883\n",
            "Epoch 217: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.4896 - val_accuracy: 0.9410 - val_loss: 0.2464\n",
            "Epoch 218/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.5233 \n",
            "Epoch 218: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.5133 - val_accuracy: 0.9424 - val_loss: 0.2471\n",
            "Epoch 218: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d0828aea50>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2525 \n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "[1.9336378e-02 4.7780275e-02 9.3255270e-01 3.0457546e-04 1.0179235e-05\n",
            " 1.5733163e-05 6.1343881e-14]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAH5CAYAAACWFaT0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAU6ZJREFUeJzt3XlcVNX7B/DPwLAICMqOC2ru5A4qpGYqioZbbmWa5vpVccM0o0y0TMw1za3UXCozrSw1N0IzTXDBXHLBXVRkE2VnWOb+/vDn1DSUjHLncpjPu9d9veJu8xzuODzznHPPVUmSJIGIiIhIYBZKB0BERET0rJjQEBERkfCY0BAREZHwmNAQERGR8JjQEBERkfCY0BAREZHwmNAQERGR8JjQEBERkfDUSgfwWOa4bkqHoIjKa88qHYIiVEoHoBBLC0ulQ1CESmWeV7ygqFDpEBRhZVlm/rSYVG7uLZO9VkHqddnObeX6nGznlhMrNERERCQ880yjiYiIRKYtUjqCMocVGiIiIhIeKzRERESikbRKR1DmsEJDREREwmOFhoiISDRaVmj+iQkNERGRYCR2ORlglxMREREJjxUaIiIi0bDLyQArNERERCQ8VmiIiIhEwzE0BlihISIiIuGxQkNERCQaPvrAACs0REREJDxWaIiIiETDMTQGWKEhIiIi4bFCQ0REJBrOQ2OACQ0REZFg+OgDQ+xyIiIiIuGxQkNERCQadjkZYIWGiIiIhMcKDRERkWg4hsYAKzREREQkPFZoiIiIRMNHHxhghYaIiIiExwoNERGRaDiGxgATGiIiItHwtm0D5bLLyapdMOzeWwmHRd/DYdH3sJu6GJY+fgAAlbM7Kq7cU+yibt720QnsK6JCyIewn/sVHJbugP1Hm2AzYCxga6dgq57d9LfHI/roz3hwPw4Jd87g++/WoV692kqHZXLTpoWgIP8uFi2crXQosnNwsMeCBeG4fPkoHjy4jIMHf4CvbxOlwypVbdq0wnffrcP168eRm3sLPXp00dveq1dX7Nz5Je7cOY3c3Fto0sRHoUhNY+yYobh6OQZZGddw9MhOtPRrpnRIpYrXm/5NuUxotA9ToflxPbLnTUD2xxNRePkMKoyZCQsvb0gPUpH1zut6i2bnl5DyclB44eT/n0BC4dkY5K6ejezZI5G3aTEsGzSH7cDxyjbsGb3Yzh+rVm1Em3Y90PXlgbBSW2HPz5thZ1dB6dBMxs+3KUaNHIyzZy8oHYpJrFo1H506tcPw4ZPh69sZUVGHsXv3ZlSp4qF0aKXG3t4O585dxOTJ7xe73c6uAo4ePYEZM+aZODLT69+/JxYuCMeHcxajZeuuOHP2Anb//DXc3FyUDq3U8Hr/P0kr3yKoctnlVHTumN7P+Ts2wrpdMCxrNYD2XjykjAd629XNXkDBqcOAJu/RitwsFBz++a/zpSWj4LddsO7cT/bY5RTcY7Dez8NHTkZiwjn4tmiCw0eO/ctR5Ye9vR02blqOMWPfxrthE5UOR3a2tjZ45ZVu6NdvJI4cOQ4AmDNnCV5+ORCjR7+BWbMWKhxh6di//1fs3//rv27/5pvtAABv72omikg5oZNGYe26zdi4aSsAYFzIO3i5WycMe/M1zF+wQuHoSgevN/0boys0qampmD9/Pl555RUEBAQgICAAr7zyChYsWICUlBQ5Ynw2KguofdsD1rYoun7JYLNF9TqwrF4bBUf3/fspnJyhbtYGRVfOyRmpyTk5OQIA0h48VDYQE/l02Vzs2R2FAwcOKx2KSajVaqjVamg0Gr31eXl5eOGFlgpFRXKxsrJCixZNEPW397ckSYg6cAT+/r4KRkay0GrlWwRlVIXmxIkTCAoKgp2dHQIDA1GvXj0AQFJSEpYtW4Z58+Zh37598PPz+8/zaDQagw/Z/CItbCxLrwfMokpN2E1dDFhZA5pc5H7+IbSJ8Qb7WbUJQtG9eGivXzTYZjtsOtRN/aGytkXh2RjkffVJqcWnNJVKhcULZ+P334/j/Pk4pcOR3YABPdG8eSP4BwQrHYrJZGVlIzr6JMLCJuLSpatISkrBq6/2QuvWLXDt2k2lw6NS5urqDLVajeSkVL31yckpaFDf/MbKkfkxKqGZMGEC+vfvj9WrV0OlUultkyQJY8aMwYQJExAdHf2f54mIiMDs2foDMt/xq413W9Y1Jpz/pE26g+yIEKhs7aFu0Ra2Q95C7pK39ZMaK2tY+b0EzZ5vij2H5vvPkb/7a6jcq8Km1zDY9BsNzZbyUbb9dNlcPP98fbTv8IrSociuWrUqWLzoA3R7eaBBIl3ejRgRis8+W4AbN06gsLAQf/zxJ7Zu/QnNmzdWOjQiegaSxIn1/smoksiZM2cQGhpqkMwAj77xh4aG4vTp0088T1hYGNLT0/WWt1qU8jeIokJIKfegvX0V+T9tgPbudVh16KW3i7p5W8DaBoXHooo9hZTxANqkOyg6dwyabz6F9YvdoXKsXLpxKmDpJ3MQ/HIgArv0x92795QOR3YtWjSGh4cbjh/bi9ycW8jNuYX27V/A+PHDkZtzCxYW5XJsPADg+vVb6Nx5AJyd66NOHX+0a9cTarUVbtwwrFaS2FJT01BYWAh3D1e99e7ubkhMKoPDAahcmDVrFlQqld7SoEED3fa8vDyEhITAxcUFDg4O6Nu3L5KSkvTOER8fj+DgYNjZ2cHd3R3Tpk1DYWGh0bEYVaHx9PTE8ePH9YL9u+PHj8PD48l3T9jY2MDGxkZvXWYpdjcVS6WCSm2lt8rqhSAUnj0GKSu9RMcDAP5xDtEs/WQOevfqik6d++PmzdtKh2MSBw4cQbPmHfXWrV2zGHFx17Bg4QpoBe4zLqmcnFzk5OSiUiUndO78It57L0LpkKiUFRQU4NSps+jYoS127Hg0JlClUqFjh7ZYuWq9wtFRqStDdyM9//zz+OWXX3Q/q9V/pRahoaH4+eefsW3bNjg5OWH8+PHo06cPfv/9dwBAUVERgoOD4enpiaNHj+LevXsYMmQIrKysMHfuXKPiMCqhmTp1KkaPHo3Y2Fh06tRJl7wkJSUhKioKa9aswcKFyt85Yd3rTRSdPwltWjJUtnZQt3wJlnWbIHf5DN0+KjcvWNZphNyVMw2Ot3y+JVQVK0F76zIkTS4sqtSAzSsjUXj1PKS0ZFM2pVR9umwuBr7WG336DkdmZhY8PNwAAOnpmcjLy1M4OvlkZWUbjBPKzs7B/fsPyv34ocDAF6FSqXDlynXUrl0Tc+e+i7i4a9i4cavSoZUae3s71K5dU/dzzZrV0aSJDx48eIjbtxNQubITqlevCi+vR59X9eo9BwBISkpBUjmrXCxZugbr1y1B7KmzOHHiD0ycMAr29hWwYeO3SodWani9/18Z+iKmVqvh6elpsD49PR3r1q3D5s2b0bHjoy+V69evR8OGDRETEwN/f3/s378fFy5cwC+//AIPDw80a9YMH374IaZPn45Zs2bB2tq65HEYE3RISAhcXV2xZMkSrFy5EkVFj/rwLC0t4evriw0bNmDAgAHGnFIWqoqVYDt0KlSOzpDysqG9ewO5y2eg6NIfun2sArpAepiKoounDE9QoIF1266w6DcaUFtBepCCgtNHkb9f7D8CY8cMBQAciPpeb/3wEaHY9KXYbaPiOTk54sMPp6NqVU+kpaXjxx93Izx8wVOVc8uqFi2aYP/+v/5gz5//6EvKl19uw+jRUxEc3Blr1izSbf/yy0fj4ObMWYKPPvrEpLHKbdu2HXBzdcasmVPh6emGM2fOI7j7YCQnpz75YEHwesuvuBt3iutZeezKlSuoUqUKbG1tERAQgIiICHh7eyM2NhYFBQUIDAzU7dugQQN4e3sjOjoa/v7+iI6ORuPGjfV6d4KCgjB27FicP38ezZs3L3HcKkmSJCPbCuBReTM19dE/EldXV1hZPVtXTOa4bs90vKgqrz2rdAiKMByFZR4sLSyVDkERxY27MwcFReUncTSGlWW5nOLsiXJzb5nstfJif5Tt3PN2nja4cSc8PByzZs0y2HfPnj3IyspC/fr1ce/ePcyePRt3797Fn3/+iZ07d2LYsGEGyVGrVq3QoUMHfPzxxxg9ejRu3bqFffv+mjolJycH9vb22L17N7p1K3lu8NTvOisrK3h5eT3t4URERFQGhYWFYcqUKXrr/q068/eEo0mTJmjdujVq1KiBrVu3okIF085Cb55pNBERkci08t22/V/dS09SqVIl1KtXD1evXkXnzp2Rn5+Phw8folKlSrp9kpKSdGNuHt9s9HeP74IqblzOfym/96sSERGRSWVlZeHatWvw8vKCr68vrKysEBX119QocXFxiI+PR0BAAAAgICAA586dQ3LyXzfcREZGwtHRET4+xj1YlBUaIiIi0ZSR27anTp2KHj16oEaNGkhISEB4eDgsLS0xcOBAODk5YcSIEZgyZQqcnZ3h6OiICRMmICAgAP7+/gCALl26wMfHB2+88Qbmz5+PxMREzJgxAyEhIUZXiZjQEBER0VO5c+cOBg4ciPv378PNzQ1t27ZFTEwM3NweTQuyZMkSWFhYoG/fvtBoNAgKCsLKlSt1x1taWmLXrl0YO3YsAgICYG9vj6FDh+KDDz4wOpanvsuptPEuJ/Ninve88C4nc8O7nMyLSe9yipFvbiFb/1dlO7eczPNdR0REJLIy0uVUlnBQMBEREQmPFRoiIiLRlKFHH5QVrNAQERGR8FihISIiEg0rNAZYoSEiIiLhsUJDREQkGEmS79EHomKFhoiIiITHCg0REZFoOIbGABMaIiIi0XBiPQPsciIiIiLhsUJDREQkGnY5GWCFhoiIiITHCg0REZFoOIbGACs0REREJDxWaIiIiETDMTQGWKEhIiIi4bFCQ0REJBqOoTHAhIaIiEg07HIywC4nIiIiEh4rNERERKJhhcZAmUlo3L44r3QIirjS0EfpEBTR6ma80iEo4kFultIhKMLSwjyLwZUrOCgdgiLM9X1OyiozCQ0RERGVEAcFGzDPr01ERERUrrBCQ0REJBqOoTHACg0REREJjxUaIiIi0XAMjQEmNERERKJhl5MBdjkRERGR8FihISIiEg27nAywQkNERETCY4WGiIhINBxDY4AVGiIiIhIeKzRERESiYYXGACs0REREJDxWaIiIiEQjSUpHUOYwoSEiIhINu5wMsMuJiIiIhMcKDRERkWhYoTHACg0REREJjxUaIiIi0fDRBwZYoSEiIiLhsUJDREQkGo6hMcAKDREREQmPFRoiIiLRcGI9A6zQEBERkfBYoSEiIhINx9AYYEJDREQkGiY0BtjlRERERMIz24TGwcEeCxaE4/Llo3jw4DIOHvwBvr5NlA7rmVTs3x1Vt32GGr//iBq//wivTUtRoU1L3XaVtRVcwibA+9D3qBG9A+6LZsLCuVKx57Jwqojq+zej1plIWFS0N1ELSsekKaOx/+B3uHHnFC5cPYqNX69A7Tq19PapWas6Nny1HBevReP67Vis3fAJ3NxcFIpYXmPHDMXVyzHIyriGo0d2oqVfM6VDkpWFhQXCw6ci7tLvePjgCi5eOIKwsElKh1XqSvI+d3d3xYrP5uP85SO4mfAHon77Ad17dlEoYnlMf3s8oo/+jAf345Bw5wy+/24d6tWrrXRY8pO08i2CMtuEZtWq+ejUqR2GD58MX9/OiIo6jN27N6NKFQ+lQ3tqhcmpSFu6DncHhuDu6yHIO34aHktnw6p2DQCA87SxsGvvj+RpH+Le8Ldg6eYCj8Wzij2X66y3kH/5hgmjLz0vtGmFL9Z8ja6BA9C/9zBYWamxbfs62NlVAADY2VXA1u1fQIKEPj2GIjhoIKysrPDVt6uhUqkUjr509e/fEwsXhOPDOYvRsnVXnDl7Abt//rrcJm8AMHXqOIwe9QYmT34fTZt1wLvvzcVbU8YgZNwwpUMrVU96nwPA8s8+Rp26tTD4tbFo/0IP/LwjEms3fILGTRoqGHnperGdP1at2og27Xqg68sDYaW2wp6fN+v9Hsg8qCSpbNz7ZWvrbcLXskFq6kX06zcSe/ce0K0/evRn7N9/ELNmLTRZLBfr15f1/N6/fY+0JWuQHfkbavz6HZLfiUDOL4cBAFY1q6PaT18gYfBEaM5d1B1TsX932Ae9hIeffwWvNQtwq21vaDOzSzWuVjfjS/V8/8XFpTIuXY9Bz26DEH30JF7q2AZbvluDOjVaIuv/21XR0QFXb51A/1eG47dfo2WL5UFulmznLs7RIztx4uQZTJo8AwCgUqlw8/oJrFi5HvMXrDBZHJYWpvvutP2H9UhKTsWYMdN067Z88xly8/IwbJhpKzWONnYme61/vs8B4ObdU5g2ZTa2ffuTbr+4GzH4MHwhvtr0nWyxmPp9/neurs5ITDiHDh374PCRYyZ97cL8uyZ7rZzPQ2U7t93oJbKdW05mWaFRq9VQq9XQaDR66/Py8vDCCy3/5SjBWFjAvutLsKhgC82ZC7DxqQeVlRXyjp3S7VJw8zYKE5Jg0/Svb2tWz3mj0v8GI2XGx+Vm0JmjU0UAwIMH6QAAa2trSJKEfE2+bh9NngZarRat/X0ViVEOVlZWaNGiCaIOHNatkyQJUQeOwL8ctfOfomNi0aFDG9T9/+6Xxo0b4oUXWmLfvoMKRyavf77PAeD48T/Qu083VKrsBJVKhd59X4aNjQ1+P3JcqTBl5+TkCABIe/BQ2UDI5Er9Lqfbt28jPDwcX3zxxb/uo9FoDJIJSZJMVu7PyspGdPRJhIVNxKVLV5GUlIJXX+2F1q1b4Nq1myaJQS5WdWqiypfLoLK2hjYnF0mhs1FwPR7W9WtDys83qLQUpT2Apavz/x9sBbd57yJtyRoUJabAqpqXAi0oXSqVCnMi3sWx6FhcungFABB74jRysnMxc/Y0fPTBYqhUKrw/6y2o1Wp4eLopHHHpcXV1hlqtRnJSqt765OQUNKhffscYLFiwAo4VHXD27K8oKiqCpaUlZobPx5YtPyodmmyKe58DwMg3J2Pt+iW4cvM4CgoKkJuThzcHj8eN66arkJqSSqXC4oWz8fvvx3H+fJzS4cirnHzhLE2lXqFJS0vDxo0b/3OfiIgIODk56S1FRRmlHcp/GjEiFCqVCjdunEBGxlWMGzcMW7f+BK3gb5KCm3dwd8AYJAyegMxtO+H24TRYPVey7jznScNRcCMe2T9HyRyl6Xy8KBwNGtbFqOF/lWfv33+AEW9OQpduHXAz4Q9cu30Sjk6OOHP6T2i1ZaIHlp5Bv3498NrAVzBk6AS09n8ZI0aGInTy/zB4cD+lQ5NNce9zAAh7bxIcnRzRp+dQdH6pL1atWI+16z9BQ596CkUqr0+XzcXzz9fH64PHKR0KKcDoCs2OHTv+c/v169efeI6wsDBMmTJFb52b2/PGhvJMrl+/hc6dB8DOrgIcHSsiMTEZX365AjduCP7NpbAQhbcTAAD5F6/A5vn6cBz0CrL3HYLK2hoWFe31qjSWzpVRlJoGALBt2RzWdWvCPvDFRxv/v2Dm/ev3eLh2Mx6u2mTSpjyreQveR5egl9Dz5cG4l5Ckt+3XA7+jVbPOcHaujMKiQmSkZ+L85SO4dXO3QtGWvtTUNBQWFsLdw1Vvvbu7GxKTUhSKSn4REe9h4YKV2Lbt0WfV+fOX4O1dDW9PC8FXX8k3bkQp//Y+r1mrOkb+7w20bR2MuEtXAQDn/4yD/wt+GD5qEKaFhisVsiyWfjIHwS8HokOnPrh7957S4chP4LuR5GJ0QtO7d2+oVCr811jiJ3Ud2djYwMbGxqhj5JKTk4ucnFxUquSEzp1fxHvvRSgSh2wsVFBZWUNz4TKkggLYtmqOnKgjAACrGtWgruIBzZlHA4KT35oNle1f18Xm+fpw+2Aq7g0LRcEdsT4g5i14Hy9374zewW8g/tadf90vLe0BAKDti/5wdXPB3t0H/nVf0RQUFODUqbPo2KEtduzYB+DRv7OOHdpi5ar1CkcnH7sKFQwqrUVFRbAw4cBkU/mv93mFCo/u8vnn70JbVAQLi/J1N9/ST+agd6+u6NS5P27evK10OKbBarIBoxMaLy8vrFy5Er169Sp2++nTp+HrW/YHHAYGvgiVSoUrV66jdu2amDv3XcTFXcPGjVuVDu2pVZ44HLlHTqAwMRkquwpweLkjbP2aInFsGKSsHGRu3wuXqWOgzciENisHLu+EIO/0ed0dToX/SFosKz0aXFdwI77U73KS08eLwtG3X3cMeX0csrKy4e7+qEKRkZGJvLxHY7cGDuqDy3HXcP9+GvxaNsdHH7+L1Ss24NpVMW9V/zdLlq7B+nVLEHvqLE6c+AMTJ4yCvX0FbNj4rdKhyebn3b9g+vQJuH37Li5cvIymTRth0sRR2FjO2vyk9/mVy9dx/dpNLPrkA4TP+BgPHjxEt+BAtO/QBoMG/E/h6EvPp8vmYuBrvdGn73BkZmbBw+PROLj09Ezk5eUpHB2ZktEJja+vL2JjY/81oXlS9aascHJyxIcfTkfVqp5IS0vHjz/uRnj4AhQWFiod2lOzdK4E1zlvQ+3mDG1WNvIv30Di2DDkxTy6syltwSpAK8F90UyorK2QezQW9z9apnDUpW/4yNcBAD/t/kpv/YSx72DL5u0AgDp1a2FG+BRUquyE2/F3sWThaqxescHUocpu27YdcHN1xqyZU+Hp6YYzZ84juPtgJCenPvlgQYWGvo9Z4VOxdNlHcHdzxb17SVi77mt89NEnSodWqp70Pi8sLMTAfqPx/uy38NW3q2Fvb4cb1+Mxfsw7+CXyNyVClsXYMUMBAAeivtdbP3xEKDZ9Ke4X1CcSfLynHIyeh+bw4cPIzs5G165di92enZ2NkydPon379kYFYsp5aMoSueehKatMOQ9NWaLk/BxKMuU8NGWJKeehKUvM9X1u0nloPpVv4LPdhJWynVtORldo2rVr95/b7e3tjU5miIiIyAis0Bgwz69NREREVK6U+sR6REREJDMBxqqaGis0REREJDxWaIiIiETDMTQGmNAQERGJhhPrGWCXExEREQmPFRoiIiLR8FlOBlihISIiIuGxQkNERCQajqExwAoNERERCY8VGiIiIsFIvG3bACs0REREJDxWaIiIiETDMTQGWKEhIiISjaSVb3lK8+bNg0qlwuTJk3Xr8vLyEBISAhcXFzg4OKBv375ISkrSOy4+Ph7BwcGws7ODu7s7pk2bhsLCQqNfnwkNERERPZMTJ07gs88+Q5MmTfTWh4aGYufOndi2bRsOHTqEhIQE9OnTR7e9qKgIwcHByM/Px9GjR7Fx40Zs2LABM2fONDoGJjRERESi0UryLUbKysrCoEGDsGbNGlSuXFm3Pj09HevWrcPixYvRsWNH+Pr6Yv369Th69ChiYmIAAPv378eFCxfw1VdfoVmzZujWrRs+/PBDrFixAvn5+UbFwYSGiIiIdDQaDTIyMvQWjUbzr/uHhIQgODgYgYGBeutjY2NRUFCgt75Bgwbw9vZGdHQ0ACA6OhqNGzeGh4eHbp+goCBkZGTg/PnzRsXNhIaIiEg0Wq1sS0REBJycnPSWiIiIYsPYsmULTp06Vez2xMREWFtbo1KlSnrrPTw8kJiYqNvn78nM4+2PtxmDdzkRERGRTlhYGKZMmaK3zsbGxmC/27dvY9KkSYiMjIStra2pwvtXrNAQERGJRsYxNDY2NnB0dNRbiktoYmNjkZycjBYtWkCtVkOtVuPQoUNYtmwZ1Go1PDw8kJ+fj4cPH+odl5SUBE9PTwCAp6enwV1Pj39+vE9JMaEhIiIio3Xq1Annzp3D6dOndYufnx8GDRqk+38rKytERUXpjomLi0N8fDwCAgIAAAEBATh37hySk5N1+0RGRsLR0RE+Pj5GxcMuJyIiItE8w3wxpaVixYpo1KiR3jp7e3u4uLjo1o8YMQJTpkyBs7MzHB0dMWHCBAQEBMDf3x8A0KVLF/j4+OCNN97A/PnzkZiYiBkzZiAkJKTYqtB/YUJDREQkGkFmCl6yZAksLCzQt29faDQaBAUFYeXKlbrtlpaW2LVrF8aOHYuAgADY29tj6NCh+OCDD4x+LZUkSWXit2Jr6610CIq4WL++0iEootXNeKVDUMSD3CylQ1CEpYV59m472tgpHYIizPV9Xph/12Svlf1ef9nObf/RNtnOLSdWaIiIiATDp20bMs+vTURERFSulJkKTZG2SOkQFFH34gWlQ1BEvF89pUNQhPfJy0qHoIgiM/02aa5dLyqlAzAHgoyhMSVWaIiIiEh4ZaZCQ0RERCXECo0BVmiIiIhIeKzQEBERiaYMTKxX1jChISIiEg27nAywy4mIiIiExwoNERGRYCRWaAywQkNERETCY4WGiIhINKzQGGCFhoiIiITHCg0REZFozPRxIv+FFRoiIiISHis0REREouEYGgNMaIiIiETDhMYAu5yIiIhIeKzQEBERCUaSWKH5J1ZoiIiISHis0BAREYmGY2gMsEJDREREwmOFhoiISDSs0BhghYaIiIiExwoNERGRYCRWaAwwoSEiIhINExoD7HIiIiIi4bFCQ0REJBo+bNsAKzREREQkPFZoiIiIBMNBwYbMskLzv9FDcCo2EvdTL+F+6iUc/m0HgoI6KB2WyYwdMxRXL8cgK+Majh7ZiZZ+zZQO6ZnYvdITbpvWwjNyFzwjd8H18+Ww8W/11/Ze3eGyfAk8I3ehytGDUDnYG5zDql5duHyyAJ77dsJzz49wmv4WVBVsTdkM2ZS3611SbLd5tNvcP8/pL2aZ0Ny5ew/vvheB1v7d4B/wMg7++jt++P4L+PjUUzo02fXv3xMLF4TjwzmL0bJ1V5w5ewG7f/4abm4uSof21IqSU5Cxag1Shv0PKcPHQBP7B5w/ngN1rZoAAJWNDTTHjiNr09fFHm/h6gKXZQtReOcuUkaNw/0p02FVqyYqzXjHhK2QR3m83iXBdptPu83281wrybcISiWVkUd2WllXVfT1kxL/xDvvzMH6DVtM+rqm/uUfPbITJ06ewaTJMwAAKpUKN6+fwIqV6zF/wQqTxRHvJ++Hjefen5Cx/DPk7NqtW2fdvClcV3yCe126Q8rK1q2369UdFUcNQ1KPfsD//3NQP1cL7l99gaT+g1B0N6HU4vI+ebnUzlUSZeV6mxrbrWy7VSZ7peIp9XlekH/XZK/1cKB8VahK3xyU7dxyMssKzd9ZWFhgwICesLe3Q8yxWKXDkZWVlRVatGiCqAOHdeskSULUgSPw9/dVMLJSZGEB28AOUNnaIv/P8yU6RGVlBRQU6pIZAJA0GgCAddPGsoRpCmZxvYvBdptXu//OnD7PoZVxEZTRg4Jzc3MRGxsLZ2dn+Pj46G3Ly8vD1q1bMWTIkP88h0ajgeb//2A8JkkSVCrT5fWNGjXA4d92wNbWBllZ2ejXfyQuXrxistdXgqurM9RqNZKTUvXWJyenoEH92gpFVTrUz9WC6+croLK2hpSbi7SwmSi8eatEx2pi/4DjxHGwf/1VZG/9HqoKtnAcNxoAYOkibqm+PF/v/8J2m1e7AfP8PCdDRlVoLl++jIYNG+LFF19E48aN0b59e9y7d0+3PT09HcOGDXvieSIiIuDk5KS3aLWZxkf/DOLirsGvZRe0adMdn32+CV+s+wQNG9Y1aQxUegrjbyNl6EikjhqH7O0/odKMd6CuWaNkx964iYcfzoPDwAHwOrAXnju/R1HCPRTdTwMkgb+uEJkJc/w8l7SSbIuojEpopk+fjkaNGiE5ORlxcXGoWLEi2rRpg/j4eKNeNCwsDOnp6XqLhUVFo87xrAoKCnDt2k2c+uMcZsyYh7NnL2DC+JEmjcHUUlPTUFhYCHcPV7317u5uSExKUSiqUlJYiKK7CSiIu4zM1WtRePUa7Af0LfHhuZFRSOrRF0m9+iOxWy9krtsIi0pOKLx778kHl1Hl+nr/B7bbvNoNmOfnObucDBmV0Bw9ehQRERFwdXVFnTp1sHPnTgQFBaFdu3a4fv16ic9jY2MDR0dHvcWU3U3FsbCwgI2NtaIxyK2goACnTp1Fxw5tdetUKhU6dmiLmJhy1t9soXo0NsZI2gcPIOXmwbZTB0j5+dCcOClDcKZhVtf7b9hu82p3cczh85wMGTWGJjc3F2r1X4eoVCqsWrUK48ePR/v27bF58+ZSD1AOc+a8g717D+L27buoWNEBr73WG+3bB+Dl4NeVDk12S5auwfp1SxB76ixOnPgDEyeMgr19BWzY+K3SoT21imNGQhNzHEWJSVDZ2aFCl06wbt4MaaFvAwAsnCvDwsUZ6mqP7qSzqv0ctDk5KEpMhpT5qKvTrm9vFJw7D21uLmxa+sFx/P+QuWqN3t1QIiqP17sk2G7zabe5fp6L3DUkF6MSmgYNGuDkyZNo2LCh3vrly5cDAHr27Fl6kcnI3c0V679YCi8vd6SnZ+LcuYt4Ofh1REUdfvLBgtu2bQfcXJ0xa+ZUeHq64cyZ8wjuPhjJyalPPriMsqhcGZXeD4OlizO02dkovHodaaFvQ3Pi0bdS+1d6ouKIN3X7u65aBgB4MGcecnfvAwBY+zSE48g3oapQAYW3biN9/mLk7o00eVtKW3m83iXBdptPu83585z0GTUPTUREBA4fPozdu3cXu33cuHFYvXo1tFrjO+GUnodGKeaaY8s9D01ZZep5aIiUoPQ8NEox5Tw0ab3ay3Zu558OyXZuOXFiPYWViV++ApjQEJVfTGjkx4TGEB9OSUREJBjOKGHI7GcKJiIiIvGxQkNERCQaVmgMMKEhIiISDLucDLHLiYiIiITHCg0REZFoWKExwAoNERERCY8VGiIiIsFwDI0hVmiIiIhIeKzQEBERCYYVGkOs0BAREZHwWKEhIiISDCs0hpjQEBERiUYy10eA/jt2OREREZHwWKEhIiISDLucDLFCQ0RERMJjhYaIiEgwkpZjaP6JFRoiIiISHis0REREguEYGkOs0BAREZHwWKEhIiISjMR5aAwwoSEiIhIMu5wMscuJiIiIhMcKDRERkWB427YhVmiIiIhIeKzQEBERCUaSlI6g7CkzCQ2vjXnxPnlZ6RAU0dKtntIhKOJEinleb3PFz3NSQplJaIiIiKhkOIbGEMfQEBERkfBYoSEiIhIMKzSGmNAQEREJhoOCDbHLiYiIiITHhIaIiEgwklYl22KMVatWoUmTJnB0dISjoyMCAgKwZ88e3fa8vDyEhITAxcUFDg4O6Nu3L5KSkvTOER8fj+DgYNjZ2cHd3R3Tpk1DYWGh0b8TJjRERET0VKpVq4Z58+YhNjYWJ0+eRMeOHdGrVy+cP38eABAaGoqdO3di27ZtOHToEBISEtCnTx/d8UVFRQgODkZ+fj6OHj2KjRs3YsOGDZg5c6bRsagkqWz0xKmtqyodApHsOA8NUflVmH/XZK91rVGQbOeuFrsDGo1Gb52NjQ1sbGxKdLyzszMWLFiAfv36wc3NDZs3b0a/fv0AAJcuXULDhg0RHR0Nf39/7NmzB927d0dCQgI8PDwAAKtXr8b06dORkpICa2vrEsfNCg0RERHpREREwMnJSW+JiIh44nFFRUXYsmULsrOzERAQgNjYWBQUFCAwMFC3T4MGDeDt7Y3o6GgAQHR0NBo3bqxLZgAgKCgIGRkZuipPSfEuJyIiIsFIWvnOHRYWhilTpuit+6/qzLlz5xAQEIC8vDw4ODhg+/bt8PHxwenTp2FtbY1KlSrp7e/h4YHExEQAQGJiol4y83j7423GYEJDREREOsZ0LwFA/fr1cfr0aaSnp+O7777D0KFDcejQIRkjLB4TGiIiIsFopbIzsZ61tTXq1KkDAPD19cWJEyewdOlSvPrqq8jPz8fDhw/1qjRJSUnw9PQEAHh6euL48eN653t8F9TjfUqKY2iIiIgEI0kq2ZZnpdVqodFo4OvrCysrK0RFRem2xcXFIT4+HgEBAQCAgIAAnDt3DsnJybp9IiMj4ejoCB8fH6NelxUaIiIieiphYWHo1q0bvL29kZmZic2bN+PXX3/Fvn374OTkhBEjRmDKlClwdnaGo6MjJkyYgICAAPj7+wMAunTpAh8fH7zxxhuYP38+EhMTMWPGDISEhBjV7QUwoSEiIhJOWXmWU3JyMoYMGYJ79+7ByckJTZo0wb59+9C5c2cAwJIlS2BhYYG+fftCo9EgKCgIK1eu1B1vaWmJXbt2YezYsQgICIC9vT2GDh2KDz74wOhYOA8NkQlxHhqi8suU89BcqveybOducHm3bOeWEys0REREgikbpYiyhYOCiYiISHis0BAREQmmrIyhKUtYoSEiIiLhsUJDREQkmLI0sV5ZwYSGiIhIMKUxAV55wy4nIiIiEh4rNERERILhbduGWKEhIiIi4bFCQ0REJBgOCjbECg0REREJz2wTmnZtW+PH7RsQfzMWhfl30bNnkNIhmczYMUNx9XIMsjKu4eiRnWjp10zpkEyivLfbwsICo6cNw/fRm/Hr1b3Y9vtXGDb5Dd12S7Ulxr07Gl/9sg4HruzGjthtmLk0DK4eLgpGLZ/yfr3/DdttHu2WJJVsi6jMNqGxt7fD2bMXMGHSe0qHYlL9+/fEwgXh+HDOYrRs3RVnzl7A7p+/hptb+fyj9pg5tPuNkIF4ZUgvLJqxDK+9NBQr536OQWNfQ//hfQAAthVsUb9xXaxf+iXe7Po/hI2aCe/nqmP++o8Ujrz0mcP1Lg7bbV7tJn182jYePSG1T7/h2LFjn2IxmMrRIztx4uQZTJo8AwCgUqlw8/oJrFi5HvMXrFA4OvmUlXbL+bTthRvnIi3lAeZOXaBbN/fz2dDkaTB74txij2nYtD6+2L0avVu+iqSEZNliM/XTtsvK9TY1tlvZdpvyadunqveS7dwtbv8k27nlZLYVGnNkZWWFFi2aIOrAYd06SZIQdeAI/P19FYxMXubS7nMnz8OvbQtUf64aAKCOT200bdUI0QeP/+sxDo720Gq1yMzIMlWYsjOX6/1PbLd5tVsrqWRbRGX0XU4XL15ETEwMAgIC0KBBA1y6dAlLly6FRqPB4MGD0bFjxyeeQ6PRQKPR6K2TJAkqlbi/SBG4ujpDrVYjOSlVb31ycgoa1K+tUFTyM5d2b1q+GXYOdthyaCO0RVpYWFrgs4/XYf/2X4rd39rGCuPe/R8ifzyAnKwcE0crH3O53v/EdptXu8mQUQnN3r170atXLzg4OCAnJwfbt2/HkCFD0LRpU2i1WnTp0gX79+9/YlITERGB2bNn661TWThAZelofAuICADQqcdLCOoTiPCQObhx+SbqPl8Hk2eHIDXpPnZv0+9OtVRbYs7qcKhUwPywJQpFTERPS+TBu3Ixqsvpgw8+wLRp03D//n2sX78er7/+OkaNGoXIyEhERUVh2rRpmDdv3hPPExYWhvT0dL1FZVHxqRtBJZOamobCwkK4e7jqrXd3d0NiUopCUcnPXNo9/v0x+HL5N/hlx0Fcu3QDe7+PxJY132HI+Nf19rNUW+Kj1eHwrOaJiQOnlavqDGA+1/uf2G7zajcZMiqhOX/+PN58800AwIABA5CZmYl+/frptg8aNAhnz5594nlsbGzg6Oiot7C7SX4FBQU4deosOnZoq1unUqnQsUNbxMTEKhiZvMyl3bYVbKCVtHrrtEVaqCz++rf1OJmpVqsaJr76FjIeZJg6TNmZy/X+J7bbvNrNMTSGjB5D8zjxsLCwgK2tLZycnHTbKlasiPT09NKLTkb29naoU6eW7udaNb3RtOnzSEt7gNu3ExSMTF5Llq7B+nVLEHvqLE6c+AMTJ4yCvX0FbNj4rdKhycoc2n0kMhpvThyMpLvJuB53A/Ub1cVro/tj15Y9AB4lM3M/n436jeti6tB3YWFpAWe3ygCAjIeZKCwoVDL8UmUO17s4bLd5tZv0GZXQ1KxZE1euXEHt2o8GWkVHR8Pb21u3PT4+Hl5eXqUboUz8fJsi6pfvdD8vWjgLALBx01aMGBmqUFTy27ZtB9xcnTFr5lR4errhzJnzCO4+GMnJqU8+WGDm0O7FM5Zh9NvDMXXuJDi7VEZKUip+/GonvliyCQDg5umKF4PaAAC+jFyrd+y4fpPxR/QZk8csF3O43sVhu82n3WVivpUyxqh5aFavXo3q1asjODi42O3vvvsukpOTsXbt2mK3/xcl56EhMhU556Epy0w9Dw2REkw5D01MlT6ynds/4QfZzi0nTqxHZEJMaIjKL1MmNEe9+sp27hfufS/bueXEp20TEREJhrdtG+JMwURERCQ8VmiIiIgEo33yLmaHFRoiIiISHis0REREgpHAMTT/xAoNERERCY8VGiIiIsFoy8SEK2ULKzREREQkPFZoiIiIBKPlGBoDrNAQERGR8FihISIiEgzvcjLEhIaIiEgwnFjPELuciIiISHis0BAREQmGXU6GWKEhIiIi4bFCQ0REJBiOoTHECg0REREJjxUaIiIiwbBCY4gVGiIiIhIeKzRERESC4V1OhpjQEBERCUbLfMYAu5yIiIhIeKzQEBERCYZP2zbECg0REREJjxUaIiIiwUhKB1AGsUJDREREwmOFhsiETqRcVjoERQypEqB0CIrYlBCtdAhUTnFiPUOs0BAREZHwWKEhIiISjFbFu5z+iQkNERGRYDgo2BC7nIiIiEh4rNAQEREJhoOCDbFCQ0RERMJjhYaIiEgwfDilIVZoiIiISHis0BAREQmGD6c0xAoNERERCY8VGiIiIsFwHhpDTGiIiIgEw0HBhtjlRERERMJjhYaIiEgwnFjPECs0REREJDxWaIiIiATDQcGGWKEhIiIi4bFCQ0REJBje5WSIFRoiIiISHis0REREguFdToaY0BAREQmGCY0hdjkRERGR8FihISIiEozEQcEGWKEhIiIi4TGhISIiEoxWxsUYERERaNmyJSpWrAh3d3f07t0bcXFxevvk5eUhJCQELi4ucHBwQN++fZGUlKS3T3x8PIKDg2FnZwd3d3dMmzYNhYWFRsXChIaIiIieyqFDhxASEoKYmBhERkaioKAAXbp0QXZ2tm6f0NBQ7Ny5E9u2bcOhQ4eQkJCAPn366LYXFRUhODgY+fn5OHr0KDZu3IgNGzZg5syZRsWikiSpTMygrLauqnQIRCSTIVUClA5BEZsSopUOgUyoMP+uyV5refXBsp171NV10Gg0eutsbGxgY2PzxGNTUlLg7u6OQ4cO4cUXX0R6ejrc3NywefNm9OvXDwBw6dIlNGzYENHR0fD398eePXvQvXt3JCQkwMPDAwCwevVqTJ8+HSkpKbC2ti5R3GZdoRk7ZiiuXo5BVsY1HD2yEy39mikdkkmw3Wy3yOq1aoiJa9/B4mOf44ub36F5l5Z623tNHoCPopZi1YWv8OmZDZj61Uw816yuwXmadGiBGT9GYPWlr/HpmQ0Y//nbpmqCrMrb9S4pc223HCIiIuDk5KS3RERElOjY9PR0AICzszMAIDY2FgUFBQgMDNTt06BBA3h7eyM6+lHCHx0djcaNG+uSGQAICgpCRkYGzp8/X+K4zTah6d+/JxYuCMeHcxajZeuuOHP2Anb//DXc3FyUDk1WbDfbLXq7bexscfviTXw1c22x2xOvJ+DrmWsxM2gKIvrNQOqdZEzZNAMVnR11+/h2bY2RSybgyLaDCO82FRF9Z+DYT4dN1QTZlMfrXRLm2G5JxiUsLAzp6el6S1hY2BNj0mq1mDx5Mtq0aYNGjRoBABITE2FtbY1KlSrp7evh4YHExETdPn9PZh5vf7ytpEoloSkjvVZGCZ00CmvXbcbGTVtx8eIVjAt5Bzk5uRj25mtKhyYrtpvtFr3d5379A9sXbcGpfceL3X5sxxFc+P0cUm4nI+HKHWyZsxF2jvao1qAGAMDC0gIDw4dj29wv8evX+5F04x4Srt7BiZ/F7x4qj9e7JMyx3VqVfIuNjQ0cHR31lpJ0N4WEhODPP//Eli1bTPAbMFQqCY2NjQ0uXrxYGqcyCSsrK7Ro0QRRB/76RiZJEqIOHIG/v6+CkcmL7Wa7zaHdf2dppUb7gZ2Rk5GN2xdvAgBqNHoOzl4ukCQJ4T8vwOLjaxC64T1UrVdd2WCfkbleb3Ntd1kzfvx47Nq1CwcPHkS1atV06z09PZGfn4+HDx/q7Z+UlARPT0/dPv+86+nxz4/3KQmjJtabMmVKseuLioowb948uLg8Ku8tXrz4P8+j0WgMBhxJkgSVyjQzBbm6OkOtViM5KVVvfXJyChrUr22SGJTAdrPdQPlvNwA07eiL/306GdYVbJCe/AALB3+ArAeZAAA370el7J6TBuDbORuQeicFQaN64O0ts/Fuh4nITs9SMvSnZq7X21zbXVYefSBJEiZMmIDt27fj119/Ra1atfS2+/r6wsrKClFRUejbty8AIC4uDvHx8QgIeHSzQEBAAD766CMkJyfD3d0dABAZGQlHR0f4+PiUOBajEppPPvkETZs2NegLkyQJFy9ehL29fYmSkoiICMyePVtvncrCASpLx385goio5C5G/4lZL0+Dg3NFtH8tEGNXTMGc3mHIvJ+h+4z6ecX3iN17DADwxbQVWBT9GfyCA3Boc6SSoRMJJSQkBJs3b8ZPP/2EihUr6sa8ODk5oUKFCnBycsKIESMwZcoUODs7w9HRERMmTEBAQAD8/f0BAF26dIGPjw/eeOMNzJ8/H4mJiZgxYwZCQkJK1NX1mFFdTnPnzkV6ejref/99HDx4ULdYWlpiw4YNOHjwIA4cOPDE8xQ34EhlUdGYUJ5JamoaCgsL4e7hqrfe3d0NiUkpJovD1Nhuthso/+0GgPxcDZJvJeL6H1ewfvoqaAu1aPdqJwBAesoDAEDClTu6/QvzC5FyOxkuVVyLPZ8IzPV6m2u7y8rEeqtWrUJ6ejpeeukleHl56ZZvv/1Wt8+SJUvQvXt39O3bFy+++CI8PT3xww8/6LZbWlpi165dsLS0REBAAAYPHowhQ4bggw8+MCoWoxKad955B99++y3Gjh2LqVOnoqCgwKgXe6y4AUem6m4CgIKCApw6dRYdO7TVrVOpVOjYoS1iYmJNFoepsd1stzm0uzgqCxWsrK0AADfPXUeBJh+ez1XRbbdUW8Klqhvu3xX3D6C5Xm9zbXdZIUlSscubb76p28fW1hYrVqxAWloasrOz8cMPPxiMjalRowZ2796NnJwcpKSkYOHChVCrjXvcpNEPp2zZsiViY2MREhICPz8/fP311yZNRkrLkqVrsH7dEsSeOosTJ/7AxAmjYG9fARs2fvvkgwXGdrPdorfbxs4W7jX/+jB0re6B6j41kf0wC1kPMtF9fF+c/uUE0pMfwKGyIzoO6YrKns448fNRAEBeVi5+/Xo/eoW+irR793H/bgq6ju4JAMLf6VQer3dJmGO7xbu3WH5P9bRtBwcHbNy4EVu2bEFgYCCKiopKOy7Zbdu2A26uzpg1cyo8Pd1w5sx5BHcfjOTk1CcfLDC2m+0Wvd01m9TG9C1/jcEb+P6bAIAj3x3Epvc+h1ftqmjTtz0cKjsi+2Embpy9hoj+7+t1MW2d+yWKCrUYuXgCrG2tcf30FSx4fRZyMrL/+XJCKY/XuyTMtd2k75kffXDnzh3ExsYiMDAQ9vb2T30ePvqAqPziow/IHJjy0Qfza8j36IO3b30l27nl9FQVmr+rVq2a3j3nREREJK+yctt2WWK2jz4gIiKi8uOZKzRERERkWhwUbIgVGiIiIhIeKzRERESC0bJGY4AVGiIiIhIeKzRERESC4V1OhlihISIiIuGxQkNERCQYjqAxxISGiIhIMOxyMsQuJyIiIhIeKzRERESC0aqUjqDsYYWGiIiIhMcKDRERkWA4sZ4hVmiIiIhIeKzQEBERCYb1GUOs0BAREZHwWKEhIiISDOehMcQKDREREQmPFRoiIiLB8C4nQ0xoiIiIBMN0xhC7nIiIiEh4rNAQEREJhoOCDbFCQ0RERMJjhYaIiEgwHBRsiBUaIiIiEh4rNERERIJhfcYQExpShErpABRirh9CmxKilQ5BEfF+9ZQOQRHeJy8rHQKZISY0REREguFdToaY0BAREQlGMtt677/joGAiIiISHis0REREgmGXkyFWaIiIiEh4rNAQEREJhhPrGWKFhoiIiITHCg0REZFgWJ8xxAoNERERCY8VGiIiIsFwDI0hJjRERESC4W3bhtjlRERERMJjhYaIiEgwfPSBIVZoiIiISHis0BAREQmGY2gMsUJDREREwmOFhoiISDAcQ2OIFRoiIiISHis0REREguEYGkNMaIiIiASjldjl9E/sciIiIiLhsUJDREQkGNZnDLFCQ0RERMJjhYaIiEgwfNq2IVZoiIiISHis0BAREQmGE+sZYoWGiIiIhGfWCc3YMUNx9XIMsjKu4eiRnWjp10zpkGTXrm1r/Lh9A+JvxqIw/y569gxSOiSTmzYtBAX5d7Fo4WylQzEJc3yfA+Wv3Xav9ITbprXwjNwFz8hdcP18OWz8W/21vVd3uCxfAs/IXahy9CBUDvYG57CqVxcunyyA576d8NzzI5ymvwVVBVtTNkM25e16P4lWxkVUZpvQ9O/fEwsXhOPDOYvRsnVXnDl7Abt//hpubi5KhyYre3s7nD17ARMmvad0KIrw822KUSMH4+zZC0qHYhLm+j4vj+0uSk5Bxqo1SBn2P6QMHwNN7B9w/ngO1LVqAgBUNjbQHDuOrE1fF3u8hasLXJYtROGdu0gZNQ73p0yHVa2aqDTjHRO2Qh7l8Xo/iRaSbIuozDahCZ00CmvXbcbGTVtx8eIVjAt5Bzk5uRj25mtKhyarvfsOYmb4fPz0016lQzE5e3s7bNy0HGPGvo0HDx4qHY5JmOv7vDy2W/N7NDTRx1B05y6Kbt9B5mfrIOXmwvp5HwBA9tbvkfXlN8j/s/hk3bZNAKTCQqQvWoqi+NsouBiHh/MXo0KH9rCsWsWUTSl15fF6k/HMMqGxsrJCixZNEHXgsG6dJEmIOnAE/v6+CkZGcvp02Vzs2R2FA3+77uWZub7PzaLdFhawDewAla0t8v88X6JDVFZWQEEh8Lcp8yWNBgBg3bSxLGGagllc72JIMv4nqme6yyk7Oxtbt27F1atX4eXlhYEDB8LF5cklPo1GA83//0N6TJIkqFSqZwmnxFxdnaFWq5GclKq3Pjk5BQ3q1zZJDGRaAwb0RPPmjeAfEKx0KCZjru/z8txu9XO14Pr5CqisrSHl5iItbCYKb94q0bGa2D/gOHEc7F9/Fdlbv4eqgi0cx40GAFiW4HO7rCrP15uMY1SFxsfHB2lpaQCA27dvo1GjRggNDUVkZCTCw8Ph4+ODGzduPPE8ERERcHJy0lskbebTtYDoCapVq4LFiz7AkKETDBJpIpEUxt9GytCRSB01Dtnbf0KlGe9AXbNGyY69cRMPP5wHh4ED4HVgLzx3fo+ihHsoup8GSCIPBTVPHBRsyKiE5tKlSygsLAQAhIWFoUqVKrh16xaOHz+OW7duoUmTJnjvvScPNg0LC0N6erreorKo+HQteAqpqWkoLCyEu4er3np3dzckJqWYLA4yjRYtGsPDww3Hj+1Fbs4t5ObcQvv2L2D8+OHIzbkFC4vy2fNqru/zct3uwkIU3U1AQdxlZK5ei8Kr12A/oG+JD8+NjEJSj75I6tUfid16IXPdRlhUckLh3XsyBi2vcn29yShP/UkeHR2NWbNmwcnJCQDg4OCA2bNn48iRI0881sbGBo6OjnqLqbqbAKCgoACnTp1Fxw5tdetUKhU6dmiLmJhYk8VBpnHgwBE0a94Rfi276JaTJ0/jm2+2w69lF2i1In8n+Xfm+j43q3ZbqB6NjTGS9sEDSLl5sO3UAVJ+PjQnTsoQnGmY1fX+G0mSZFtEZfQYmseJR15eHry8vPS2Va1aFSkpYmTES5auwfp1SxB76ixOnPgDEyeMgr19BWzY+K3SocnK3t4OderU0v1cq6Y3mjZ9HmlpD3D7doKCkcknKysb58/H6a3Lzs7B/fsPDNaXN+b6Pi+P7a44ZiQ0McdRlJgElZ0dKnTpBOvmzZAW+jYAwMK5MixcnKGuVhUAYFX7OWhzclCUmAwp81GXvl3f3ig4dx7a3FzYtPSD4/j/IXPVGkhZ2Yq1qzSUx+tNxjM6oenUqRPUajUyMjIQFxeHRo0a6bbdunWrRIOCy4Jt23bAzdUZs2ZOhaenG86cOY/g7oORnJz65IMF5ufbFFG/fKf7edHCWQCAjZu2YsTIUIWiIrmY6/u8PLbbonJlVHo/DJYuztBmZ6Pw6nWkhb4NzYlHVQj7V3qi4og3dfu7rloGAHgwZx5yd+8DAFj7NITjyDehqlABhbduI33+YuTujTR5W0pbebzeTyLyfDFyUUlG1Jdmz9afWdXf3x9BQX/NNDtt2jTcuXMH33zzjdGBqK2rGn0Mict0HYxlCz+CzEu8Xz2lQ1CE98nLSoegiML8uyZ7rR7e3WU79874XbKdW05GJTRyYkJjXpjQkDlgQmNemNAoi0/bJiIiEozIE+DJpXzer0pERERmhRUaIiIiwXBQsCFWaIiIiEh4TGiIiIgEU1Ym1vvtt9/Qo0cPVKlSBSqVCj/++KNBnDNnzoSXlxcqVKiAwMBAXLlyRW+ftLQ0DBo0CI6OjqhUqRJGjBiBrKwso38nTGiIiIjoqWRnZ6Np06ZYsWJFsdvnz5+PZcuWYfXq1Th27Bjs7e0RFBSEvLw83T6DBg3C+fPnERkZiV27duG3337D6NGjjY6Ft22TInjbNpkD3rZtXkx523ZQ9W6ynXvH1R8NHuRrY2MDGxub/zxOpVJh+/bt6N27N4BH1ZkqVargrbfewtSpUwEA6enp8PDwwIYNG/Daa6/h4sWL8PHxwYkTJ+Dn5wcA2Lt3L15++WXcuXMHVapUKXHcrNAQEREJRpLxv4iICDg5OektERERRsd448YNJCYmIjAwULfOyckJrVu3RnR0NIBHz4WsVKmSLpkBgMDAQFhYWODYsWNGvR7vciIiIiKdsLAwTJkyRW/dk6ozxUlMTAQAeHh46K338PDQbUtMTIS7u7vedrVaDWdnZ90+JcWEhoiISDBy3rZdku6lsohdTkRERFTqPD09AQBJSUl665OSknTbPD09kZycrLe9sLAQaWlpun1KigkNERGRYMrKbdv/pVatWvD09ERUVJRuXUZGBo4dO4aAgAAAQEBAAB4+fIjY2FjdPgcOHIBWq0Xr1q2Nej12OREREdFTycrKwtWrV3U/37hxA6dPn4azszO8vb0xefJkzJkzB3Xr1kWtWrXw/vvvo0qVKro7oRo2bIiuXbti1KhRWL16NQoKCjB+/Hi89tprRt3hBDChISIiEk5ZefTByZMn0aFDB93PjwcTDx06FBs2bMDbb7+N7OxsjB49Gg8fPkTbtm2xd+9e2Nra6o75+uuvMX78eHTq1AkWFhbo27cvli1bZnQsnIeGFMF5aMgccB4a82LKeWg6VOss27kP3omU7dxyYoWGiIhIMBK/HhlgQkNERCQYbdnoXClTeJcTERERCY8VGiIiIsGwPmOIFRoiIiISHis0REREgikrt22XJazQEBERkfBYoSEiIhIMKzSGWKEhIiIi4bFCQ0REJJgyMsl/mcIKDREREQmPFRpSBL9bkDkw12ca5SYcVjqEco9jaAwxoSEiIhIMn+VkiF1OREREJDxWaIiIiATDQcGGWKEhIiIi4bFCQ0REJBgOCjbECg0REREJjxUaIiIiwXAMjSFWaIiIiEh4rNAQEREJhmNoDDGhISIiEgwn1jPELiciIiISHis0REREgtFyULABVmiIiIhIeKzQEBERCYZjaAyxQkNERETCY4WGiIhIMBxDY4gVGiIiIhIeKzRERESC4RgaQ0xoiIiIBMMuJ0PsciIiIiLhsUJDREQkGHY5GWKFhoiIiITHCg0REZFgOIbGECs0REREJDxWaIiIiATDMTSGWKEhIiIi4bFCQ0REJBhJ0iodQplj1hWasWOG4urlGGRlXMPRIzvR0q+Z0iGZBNvNdpdn098ej+ijP+PB/Tgk3DmD779bh3r1aisdlsmUt+u9Yt1XaNSmm97SY+Aog/0kScKYt95HozbdEPXb0WLP9TA9A516D0ajNt2QkZkld+iy0kKSbRGV2SY0/fv3xMIF4fhwzmK0bN0VZ85ewO6fv4abm4vSocmK7Wa7y3u7X2znj1WrNqJNux7o+vJAWKmtsOfnzbCzq6B0aLIrr9e7Tq0a+HXH17pl06qFBvt8+e2PUD3hPDMjPkG92rXkCZIUZ7YJTeikUVi7bjM2btqKixevYFzIO8jJycWwN19TOjRZsd1sd3lvd3CPwdj05VZcuHAZZ89ewPCRk1GjRjX4tmiidGiyK6/X29LSEq4uzrqlciUnve2XLl/Dxi3f48N3Q//1HFu270JGVhbefL2v3OGahCRJsi2iMsuExsrKCi1aNEHUgcO6dZIkIerAEfj7+yoYmbzYbrbbHNr9T05OjgCAtAcPlQ1EZuX5esffuYsOPQeha/9hmD7rY9xLTNZty83Lw9uzP8Z7b4XA1cW52OOv3biF1es3I2LGVKhUZvlnzywYdWVPnTqFGzdu6H7+8ssv0aZNG1SvXh1t27bFli1bSnQejUaDjIwMvcWUWaGrqzPUajWSk1L11icnp8DTw81kcZga2812A+W/3X+nUqmweOFs/P77cZw/H6d0OLIqr9e7iU99zHnvLaxePAfvTx2PO/eSMGTcNGRn5wAA5i/7HM0a+aBju4Bij8/Pz8e0WR/jrZCR8PJ0N2XosuIYGkNG3eU0bNgwLFq0CLVq1cLatWsxceJEjBo1Cm+88Qbi4uIwatQo5OTkYPjw4f95noiICMyePVtvncrCASpLR+NbQET0Lz5dNhfPP18f7Tu8onQo9JTaBbTU/X/9OrXQ2Kc+uvQdir0HDsO5khOOxZ7Bd+uX/+vxn6zegOdqVEePoI6mCJcUZFRCc+XKFdStWxcAsHLlSixduhSjRv012rxly5b46KOPnpjQhIWFYcqUKXrrKrs0MCaUZ5KamobCwkK4e7jqrXd3d0NiUorJ4jA1tpvtBsp/ux9b+skcBL8ciA6d+uDu3XtKhyM7c7nejhUdUKN6VcTfScCVazdw++49BHTtp7dP6HsfoUXT57Fh+Xwciz2DK9dvoumLwQCAx50B7YJfxaghr2H8yDdM3YRSIfJYF7kY1eVkZ2eH1NRH5cy7d++iVatWettbt26t1yX1b2xsbODo6Ki3qFRPGp9eegoKCnDq1Fl07NBWt06lUqFjh7aIiYk1WRymxnaz3ebQbuBRMtO7V1d0DhqAmzdvKx2OSZjL9c7JycXtu/fg5uqMkW8MwA+bVuK7DSt0CwC8PXE05rz76Evzko/ew/cb/9o++51JAICNKxdiYN8eirWDSp9RFZpu3bph1apVWLt2Ldq3b4/vvvsOTZs21W3funUr6tSpU+pBymHJ0jVYv24JYk+dxYkTf2DihFGwt6+ADRu/VTo0WbHdbHd5b/eny+Zi4Gu90afvcGRmZsHj/8ePpKdnIi8vT+Ho5FUer/eC5WvwUpvWqOLpgeTU+1ix9itYWlrg5cD2cK5cqdiBwF4ebqhWxRMA4F2tit62Bw8zAADP1agOx4oO8jdAJnw4pSGjEpqPP/4Ybdq0Qfv27eHn54dFixbh119/RcOGDREXF4eYmBhs375drlhL1bZtO+Dm6oxZM6fC09MNZ86cR3D3wUhOTn3ywQJju9nu8t7usWOGAgAORH2vt374iFBs+nKrEiGZTHm83knJqXg7/GM8zMiAcyUnNG/yPL7+bAmcK1dSOjRF8VlOhlSSkR1xDx8+xLx587Bz505cv34dWq0WXl5eaNOmDUJDQ+Hn5/dUgaitqz7VcUREVLbkJhx+8k7lkJXrcyZ7Lc9KDWU7d+LDi7KdW05GJzRyYUJDRFQ+MKGRn4eTfDfSJKVfku3ccuIMQ0RERCQ8Pm2biIhIMCJPgCcXVmiIiIhIeKzQEBERCaaMDH8tU1ihISIiIuGxQkNERCQYTqxniAkNERGRYNjlZIhdTkRERCQ8VmiIiIgEw9u2DbFCQ0RERMJjhYaIiEgwHENjiBUaIiIiEh4rNERERILhbduGWKEhIiIi4bFCQ0REJBiJdzkZYEJDREQkGHY5GWKXExEREQmPFRoiIiLB8LZtQ6zQEBERkfBYoSEiIhIMBwUbYoWGiIiIhMcKDRERkWA4hsYQKzREREQkPCY0REREgpEkSbblaaxYsQI1a9aEra0tWrdujePHj5dyi5+MCQ0REZFgJBkXY3377beYMmUKwsPDcerUKTRt2hRBQUFITk5+hhYaTyWVkY44tXVVpUMgIqJSkJtwWOkQFGHl+pzJXkvOv5nZmdeh0Wj01tnY2MDGxqbY/Vu3bo2WLVti+fLlAACtVovq1atjwoQJeOedd2SL04Bk5vLy8qTw8HApLy9P6VBMiu1mu80B2812k/HCw8MNCjfh4eHF7qvRaCRLS0tp+/bteuuHDBki9ezZU/5g/6bMVGiUkpGRAScnJ6Snp8PR0VHpcEyG7Wa7zQHbzXaT8TQaTYkrNAkJCahatSqOHj2KgIAA3fq3334bhw4dwrFjx2SP9zHetk1EREQ6/9W9VJZxUDARERE9FVdXV1haWiIpKUlvfVJSEjw9PU0aCxMaIiIieirW1tbw9fVFVFSUbp1Wq0VUVJReF5QpmH2Xk42NDcLDw4Usrz0LtpvtNgdsN9tN8psyZQqGDh0KPz8/tGrVCp988gmys7MxbNgwk8Zh9oOCiYiI6NksX74cCxYsQGJiIpo1a4Zly5ahdevWJo2BCQ0REREJj2NoiIiISHhMaIiIiEh4TGiIiIhIeExoiIiISHhmndCUhcedm9pvv/2GHj16oEqVKlCpVPjxxx+VDkl2ERERaNmyJSpWrAh3d3f07t0bcXFxSoclu1WrVqFJkyZwdHSEo6MjAgICsGfPHqXDMrl58+ZBpVJh8uTJSociq1mzZkGlUuktDRo0UDosk7h79y4GDx4MFxcXVKhQAY0bN8bJkyeVDotMzGwTmrLyuHNTy87ORtOmTbFixQqlQzGZQ4cOISQkBDExMYiMjERBQQG6dOmC7OxspUOTVbVq1TBv3jzExsbi5MmT6NixI3r16oXz588rHZrJnDhxAp999hmaNGmidCgm8fzzz+PevXu65ciRI0qHJLsHDx6gTZs2sLKywp49e3DhwgUsWrQIlStXVjo0MjWTPgqzDGnVqpUUEhKi+7moqEiqUqWKFBERoWBUpgXA4Amp5iA5OVkCIB06dEjpUEyucuXK0tq1a5UOwyQyMzOlunXrSpGRkVL79u2lSZMmKR2SrMLDw6WmTZsqHYbJTZ8+XWrbtq3SYVAZYJYVmvz8fMTGxiIwMFC3zsLCAoGBgYiOjlYwMjKF9PR0AICzs7PCkZhOUVERtmzZguzsbJNPR66UkJAQBAcH6/07L++uXLmCKlWq4LnnnsOgQYMQHx+vdEiy27FjB/z8/NC/f3+4u7ujefPmWLNmjdJhkQLMMqFJTU1FUVERPDw89NZ7eHggMTFRoajIFLRaLSZPnow2bdqgUaNGSocju3PnzsHBwQE2NjYYM2YMtm/fDh8fH6XDkt2WLVtw6tQpREREKB2KybRu3RobNmzA3r17sWrVKty4cQPt2rVDZmam0qHJ6vr161i1ahXq1q2Lffv2YezYsZg4cSI2btyodGhkYmb/LCcyLyEhIfjzzz/NYmwBANSvXx+nT59Geno6vvvuOwwdOhSHDh0q10nN7du3MWnSJERGRsLW1lbpcEymW7duuv9v0qQJWrdujRo1amDr1q0YMWKEgpHJS6vVws/PD3PnzgUANG/eHH/++SdWr16NoUOHKhwdmZJZVmjK0uPOyXTGjx+PXbt24eDBg6hWrZrS4ZiEtbU16tSpA19fX0RERKBp06ZYunSp0mHJKjY2FsnJyWjRogXUajXUajUOHTqEZcuWQa1Wo6ioSOkQTaJSpUqoV68erl69qnQosvLy8jJI0Bs2bGgW3W2kzywTmrL0uHOSnyRJGD9+PLZv344DBw6gVq1aSoekGK1WC41Go3QYsurUqRPOnTuH06dP6xY/Pz8MGjQIp0+fhqWlpdIhmkRWVhauXbsGLy8vpUORVZs2bQymYbh8+TJq1KihUESkFLPtciorjzs3taysLL1vbDdu3MDp06fh7OwMb29vBSOTT0hICDZv3oyffvoJFStW1I2TcnJyQoUKFRSOTj5hYWHo1q0bvL29kZmZic2bN+PXX3/Fvn37lA5NVhUrVjQYH2Vvbw8XF5dyPW5q6tSp6NGjB2rUqIGEhASEh4fD0tISAwcOVDo0WYWGhuKFF17A3LlzMWDAABw/fhyff/45Pv/8c6VDI1NT+jYrJX366aeSt7e3ZG1tLbVq1UqKiYlROiTZHTx4UAJgsAwdOlTp0GRTXHsBSOvXr1c6NFkNHz5cqlGjhmRtbS25ublJnTp1kvbv3690WIowh9u2X331VcnLy0uytraWqlatKr366qvS1atXlQ7LJHbu3Ck1atRIsrGxkRo0aCB9/vnnSodEClBJkiQplEsRERERlQqzHENDRERE5QsTGiIiIhIeExoiIiISHhMaIiIiEh4TGiIiIhIeExoiIiISHhMaIiIiEh4TGiIiIhIeExoiIiISHhMaIiIiEh4TGiIiIhLe/wF2ibVmN7GL1QAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94       410\n",
            "           1       0.99      0.80      0.89       380\n",
            "           2       0.90      0.98      0.94       325\n",
            "           3       0.90      0.99      0.94        83\n",
            "           4       0.87      1.00      0.93       136\n",
            "           5       0.92      0.98      0.95       324\n",
            "           6       0.97      1.00      0.98       546\n",
            "\n",
            "    accuracy                           0.94      2204\n",
            "   macro avg       0.93      0.95      0.94      2204\n",
            "weighted avg       0.95      0.94      0.94      2204\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpn7qq6r4u/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpn7qq6r4u/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpn7qq6r4u'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 7), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132836941590224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132836941594256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132836939039952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132836939054544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132836939042448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132836939053392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1744682557.792284   79634 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1744682557.792306   79634 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2025-04-15 09:02:37.792645: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpn7qq6r4u\n",
            "2025-04-15 09:02:37.793168: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-04-15 09:02:37.793175: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpn7qq6r4u\n",
            "I0000 00:00:1744682557.797466   79634 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
            "2025-04-15 09:02:37.798534: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-04-15 09:02:37.818298: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpn7qq6r4u\n",
            "2025-04-15 09:02:37.824527: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 31885 microseconds.\n",
            "2025-04-15 09:02:37.835528: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6688"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/01DB783D25219E60/HOMEWORK/TGMT/ThiGiacPC/AI/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.54 ms, sys: 0 ns, total: 1.54 ms\n",
            "Wall time: 1.17 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.9336378e-02 4.7780249e-02 9.3255287e-01 3.0457554e-04 1.0179237e-05\n",
            " 1.5733165e-05 6.1343888e-14]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
